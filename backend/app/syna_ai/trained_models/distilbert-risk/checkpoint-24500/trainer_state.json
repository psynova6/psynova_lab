{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.98,
  "eval_steps": 500,
  "global_step": 24500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.002,
      "grad_norm": 3.2642650604248047,
      "learning_rate": 1.9960800000000004e-05,
      "loss": 0.6661978149414063,
      "step": 50
    },
    {
      "epoch": 0.004,
      "grad_norm": 8.891775131225586,
      "learning_rate": 1.99208e-05,
      "loss": 0.4037997817993164,
      "step": 100
    },
    {
      "epoch": 0.006,
      "grad_norm": 14.20781421661377,
      "learning_rate": 1.98808e-05,
      "loss": 0.3256052398681641,
      "step": 150
    },
    {
      "epoch": 0.008,
      "grad_norm": 3.2825608253479004,
      "learning_rate": 1.98408e-05,
      "loss": 0.3385674285888672,
      "step": 200
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.386429786682129,
      "learning_rate": 1.9800800000000002e-05,
      "loss": 0.3152022361755371,
      "step": 250
    },
    {
      "epoch": 0.012,
      "grad_norm": 14.782569885253906,
      "learning_rate": 1.9760800000000002e-05,
      "loss": 0.27462703704833985,
      "step": 300
    },
    {
      "epoch": 0.014,
      "grad_norm": 4.809315204620361,
      "learning_rate": 1.9720800000000003e-05,
      "loss": 0.30563819885253907,
      "step": 350
    },
    {
      "epoch": 0.016,
      "grad_norm": 0.216054767370224,
      "learning_rate": 1.9680800000000003e-05,
      "loss": 0.2491111946105957,
      "step": 400
    },
    {
      "epoch": 0.018,
      "grad_norm": 16.67820930480957,
      "learning_rate": 1.9640800000000003e-05,
      "loss": 0.2306443977355957,
      "step": 450
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5276236534118652,
      "learning_rate": 1.96008e-05,
      "loss": 0.2677998352050781,
      "step": 500
    },
    {
      "epoch": 0.022,
      "grad_norm": 0.1539953202009201,
      "learning_rate": 1.95608e-05,
      "loss": 0.24269487380981444,
      "step": 550
    },
    {
      "epoch": 0.024,
      "grad_norm": 1.5274213552474976,
      "learning_rate": 1.95208e-05,
      "loss": 0.2211168098449707,
      "step": 600
    },
    {
      "epoch": 0.026,
      "grad_norm": 9.977607727050781,
      "learning_rate": 1.94808e-05,
      "loss": 0.24772872924804687,
      "step": 650
    },
    {
      "epoch": 0.028,
      "grad_norm": 1.699532151222229,
      "learning_rate": 1.9440800000000002e-05,
      "loss": 0.2561589622497559,
      "step": 700
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.24198365211486816,
      "learning_rate": 1.9400800000000002e-05,
      "loss": 0.22545730590820312,
      "step": 750
    },
    {
      "epoch": 0.032,
      "grad_norm": 1.7053533792495728,
      "learning_rate": 1.9360800000000003e-05,
      "loss": 0.2521753120422363,
      "step": 800
    },
    {
      "epoch": 0.034,
      "grad_norm": 0.35823050141334534,
      "learning_rate": 1.9320800000000003e-05,
      "loss": 0.18121402740478515,
      "step": 850
    },
    {
      "epoch": 0.036,
      "grad_norm": 10.702132225036621,
      "learning_rate": 1.92808e-05,
      "loss": 0.21912820816040038,
      "step": 900
    },
    {
      "epoch": 0.038,
      "grad_norm": 0.07653883099555969,
      "learning_rate": 1.92408e-05,
      "loss": 0.18985488891601562,
      "step": 950
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.682775616645813,
      "learning_rate": 1.92008e-05,
      "loss": 0.17316558837890625,
      "step": 1000
    },
    {
      "epoch": 0.042,
      "grad_norm": 26.283143997192383,
      "learning_rate": 1.91608e-05,
      "loss": 0.2182131004333496,
      "step": 1050
    },
    {
      "epoch": 0.044,
      "grad_norm": 24.110862731933594,
      "learning_rate": 1.91208e-05,
      "loss": 0.23634532928466798,
      "step": 1100
    },
    {
      "epoch": 0.046,
      "grad_norm": 0.5893036723136902,
      "learning_rate": 1.9080800000000002e-05,
      "loss": 0.2291337013244629,
      "step": 1150
    },
    {
      "epoch": 0.048,
      "grad_norm": 1.3748588562011719,
      "learning_rate": 1.9040800000000002e-05,
      "loss": 0.18773792266845704,
      "step": 1200
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.12232862412929535,
      "learning_rate": 1.9000800000000003e-05,
      "loss": 0.22269733428955077,
      "step": 1250
    },
    {
      "epoch": 0.052,
      "grad_norm": 12.69335651397705,
      "learning_rate": 1.89608e-05,
      "loss": 0.21906425476074218,
      "step": 1300
    },
    {
      "epoch": 0.054,
      "grad_norm": 0.8470968008041382,
      "learning_rate": 1.89208e-05,
      "loss": 0.2427789306640625,
      "step": 1350
    },
    {
      "epoch": 0.056,
      "grad_norm": 2.210242509841919,
      "learning_rate": 1.88808e-05,
      "loss": 0.3007530212402344,
      "step": 1400
    },
    {
      "epoch": 0.058,
      "grad_norm": 0.37381669878959656,
      "learning_rate": 1.88408e-05,
      "loss": 0.2416543960571289,
      "step": 1450
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.110907793045044,
      "learning_rate": 1.88008e-05,
      "loss": 0.11931100845336914,
      "step": 1500
    },
    {
      "epoch": 0.062,
      "grad_norm": 4.352095603942871,
      "learning_rate": 1.8760800000000002e-05,
      "loss": 0.28457298278808596,
      "step": 1550
    },
    {
      "epoch": 0.064,
      "grad_norm": 4.804773330688477,
      "learning_rate": 1.8720800000000002e-05,
      "loss": 0.1384908676147461,
      "step": 1600
    },
    {
      "epoch": 0.066,
      "grad_norm": 11.614980697631836,
      "learning_rate": 1.8680800000000002e-05,
      "loss": 0.29650178909301755,
      "step": 1650
    },
    {
      "epoch": 0.068,
      "grad_norm": 3.653247833251953,
      "learning_rate": 1.86408e-05,
      "loss": 0.16083002090454102,
      "step": 1700
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.15907783806324005,
      "learning_rate": 1.86008e-05,
      "loss": 0.23135059356689452,
      "step": 1750
    },
    {
      "epoch": 0.072,
      "grad_norm": 0.13986752927303314,
      "learning_rate": 1.85608e-05,
      "loss": 0.22493160247802735,
      "step": 1800
    },
    {
      "epoch": 0.074,
      "grad_norm": 17.04096221923828,
      "learning_rate": 1.85208e-05,
      "loss": 0.1559079647064209,
      "step": 1850
    },
    {
      "epoch": 0.076,
      "grad_norm": 0.4669128656387329,
      "learning_rate": 1.84808e-05,
      "loss": 0.22451242446899414,
      "step": 1900
    },
    {
      "epoch": 0.078,
      "grad_norm": 0.11237070709466934,
      "learning_rate": 1.84408e-05,
      "loss": 0.2411009407043457,
      "step": 1950
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.05767320096492767,
      "learning_rate": 1.8400800000000002e-05,
      "loss": 0.2314455795288086,
      "step": 2000
    },
    {
      "epoch": 0.082,
      "grad_norm": 14.623010635375977,
      "learning_rate": 1.8360800000000002e-05,
      "loss": 0.19961374282836913,
      "step": 2050
    },
    {
      "epoch": 0.084,
      "grad_norm": 2.266186237335205,
      "learning_rate": 1.83208e-05,
      "loss": 0.1846613883972168,
      "step": 2100
    },
    {
      "epoch": 0.086,
      "grad_norm": 26.145292282104492,
      "learning_rate": 1.82808e-05,
      "loss": 0.220292911529541,
      "step": 2150
    },
    {
      "epoch": 0.088,
      "grad_norm": 0.10959634184837341,
      "learning_rate": 1.82408e-05,
      "loss": 0.22656234741210937,
      "step": 2200
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.11274225264787674,
      "learning_rate": 1.82008e-05,
      "loss": 0.21840675354003905,
      "step": 2250
    },
    {
      "epoch": 0.092,
      "grad_norm": 12.42280387878418,
      "learning_rate": 1.81608e-05,
      "loss": 0.1989332389831543,
      "step": 2300
    },
    {
      "epoch": 0.094,
      "grad_norm": 28.897510528564453,
      "learning_rate": 1.81208e-05,
      "loss": 0.16523681640625,
      "step": 2350
    },
    {
      "epoch": 0.096,
      "grad_norm": 4.211800575256348,
      "learning_rate": 1.80808e-05,
      "loss": 0.28707361221313477,
      "step": 2400
    },
    {
      "epoch": 0.098,
      "grad_norm": 23.770246505737305,
      "learning_rate": 1.8040800000000002e-05,
      "loss": 0.19532773971557618,
      "step": 2450
    },
    {
      "epoch": 0.1,
      "grad_norm": 13.276684761047363,
      "learning_rate": 1.80008e-05,
      "loss": 0.22951812744140626,
      "step": 2500
    },
    {
      "epoch": 0.102,
      "grad_norm": 5.743566989898682,
      "learning_rate": 1.79608e-05,
      "loss": 0.21997840881347655,
      "step": 2550
    },
    {
      "epoch": 0.104,
      "grad_norm": 4.750324726104736,
      "learning_rate": 1.79208e-05,
      "loss": 0.17147838592529296,
      "step": 2600
    },
    {
      "epoch": 0.106,
      "grad_norm": 0.20041610300540924,
      "learning_rate": 1.78808e-05,
      "loss": 0.14908123016357422,
      "step": 2650
    },
    {
      "epoch": 0.108,
      "grad_norm": 24.526899337768555,
      "learning_rate": 1.7840800000000004e-05,
      "loss": 0.20215744018554688,
      "step": 2700
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.3439244031906128,
      "learning_rate": 1.7800800000000004e-05,
      "loss": 0.23940061569213866,
      "step": 2750
    },
    {
      "epoch": 0.112,
      "grad_norm": 0.6017295718193054,
      "learning_rate": 1.77608e-05,
      "loss": 0.2634058380126953,
      "step": 2800
    },
    {
      "epoch": 0.114,
      "grad_norm": 28.523569107055664,
      "learning_rate": 1.77208e-05,
      "loss": 0.17331111907958985,
      "step": 2850
    },
    {
      "epoch": 0.116,
      "grad_norm": 0.46440374851226807,
      "learning_rate": 1.7680800000000002e-05,
      "loss": 0.13601369857788087,
      "step": 2900
    },
    {
      "epoch": 0.118,
      "grad_norm": 0.4381876289844513,
      "learning_rate": 1.7640800000000002e-05,
      "loss": 0.22721197128295897,
      "step": 2950
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.23104000091552734,
      "learning_rate": 1.7600800000000003e-05,
      "loss": 0.18158458709716796,
      "step": 3000
    },
    {
      "epoch": 0.122,
      "grad_norm": 0.05502287670969963,
      "learning_rate": 1.7560800000000003e-05,
      "loss": 0.1367347526550293,
      "step": 3050
    },
    {
      "epoch": 0.124,
      "grad_norm": 0.13931109011173248,
      "learning_rate": 1.7520800000000003e-05,
      "loss": 0.21029054641723632,
      "step": 3100
    },
    {
      "epoch": 0.126,
      "grad_norm": 0.33108046650886536,
      "learning_rate": 1.7480800000000004e-05,
      "loss": 0.16127098083496094,
      "step": 3150
    },
    {
      "epoch": 0.128,
      "grad_norm": 13.726479530334473,
      "learning_rate": 1.74408e-05,
      "loss": 0.24829010009765626,
      "step": 3200
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.08020410686731339,
      "learning_rate": 1.74008e-05,
      "loss": 0.2094196128845215,
      "step": 3250
    },
    {
      "epoch": 0.132,
      "grad_norm": 5.706437587738037,
      "learning_rate": 1.73608e-05,
      "loss": 0.13093104362487792,
      "step": 3300
    },
    {
      "epoch": 0.134,
      "grad_norm": 0.2637178599834442,
      "learning_rate": 1.7320800000000002e-05,
      "loss": 0.1830927848815918,
      "step": 3350
    },
    {
      "epoch": 0.136,
      "grad_norm": 11.97945785522461,
      "learning_rate": 1.7280800000000002e-05,
      "loss": 0.136983003616333,
      "step": 3400
    },
    {
      "epoch": 0.138,
      "grad_norm": 0.14685608446598053,
      "learning_rate": 1.7240800000000003e-05,
      "loss": 0.23723905563354492,
      "step": 3450
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.2012287974357605,
      "learning_rate": 1.7200800000000003e-05,
      "loss": 0.24494686126708984,
      "step": 3500
    },
    {
      "epoch": 0.142,
      "grad_norm": 5.938170433044434,
      "learning_rate": 1.7160800000000003e-05,
      "loss": 0.2303781509399414,
      "step": 3550
    },
    {
      "epoch": 0.144,
      "grad_norm": 0.17124955356121063,
      "learning_rate": 1.71208e-05,
      "loss": 0.20340724945068359,
      "step": 3600
    },
    {
      "epoch": 0.146,
      "grad_norm": 0.15677370131015778,
      "learning_rate": 1.70808e-05,
      "loss": 0.17471818923950194,
      "step": 3650
    },
    {
      "epoch": 0.148,
      "grad_norm": 0.22540342807769775,
      "learning_rate": 1.70408e-05,
      "loss": 0.3393534469604492,
      "step": 3700
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.12842561304569244,
      "learning_rate": 1.70008e-05,
      "loss": 0.1949964141845703,
      "step": 3750
    },
    {
      "epoch": 0.152,
      "grad_norm": 0.12306090444326401,
      "learning_rate": 1.6960800000000002e-05,
      "loss": 0.19176036834716798,
      "step": 3800
    },
    {
      "epoch": 0.154,
      "grad_norm": 4.422205448150635,
      "learning_rate": 1.6920800000000002e-05,
      "loss": 0.16822153091430664,
      "step": 3850
    },
    {
      "epoch": 0.156,
      "grad_norm": 0.4639194905757904,
      "learning_rate": 1.6880800000000003e-05,
      "loss": 0.16417346954345702,
      "step": 3900
    },
    {
      "epoch": 0.158,
      "grad_norm": 0.0393863245844841,
      "learning_rate": 1.6840800000000003e-05,
      "loss": 0.21965436935424804,
      "step": 3950
    },
    {
      "epoch": 0.16,
      "grad_norm": 18.105688095092773,
      "learning_rate": 1.68008e-05,
      "loss": 0.17329492568969726,
      "step": 4000
    },
    {
      "epoch": 0.162,
      "grad_norm": 55.0877685546875,
      "learning_rate": 1.67608e-05,
      "loss": 0.14614362716674806,
      "step": 4050
    },
    {
      "epoch": 0.164,
      "grad_norm": 0.8712840676307678,
      "learning_rate": 1.67208e-05,
      "loss": 0.21083196640014648,
      "step": 4100
    },
    {
      "epoch": 0.166,
      "grad_norm": 17.02340316772461,
      "learning_rate": 1.66808e-05,
      "loss": 0.12616556167602538,
      "step": 4150
    },
    {
      "epoch": 0.168,
      "grad_norm": 12.529678344726562,
      "learning_rate": 1.66408e-05,
      "loss": 0.2568185615539551,
      "step": 4200
    },
    {
      "epoch": 0.17,
      "grad_norm": 27.632360458374023,
      "learning_rate": 1.6600800000000002e-05,
      "loss": 0.20080286026000976,
      "step": 4250
    },
    {
      "epoch": 0.172,
      "grad_norm": 9.25940990447998,
      "learning_rate": 1.6560800000000002e-05,
      "loss": 0.22032384872436522,
      "step": 4300
    },
    {
      "epoch": 0.174,
      "grad_norm": 2.688854217529297,
      "learning_rate": 1.6520800000000003e-05,
      "loss": 0.14918444633483888,
      "step": 4350
    },
    {
      "epoch": 0.176,
      "grad_norm": 32.345794677734375,
      "learning_rate": 1.64808e-05,
      "loss": 0.20655818939208984,
      "step": 4400
    },
    {
      "epoch": 0.178,
      "grad_norm": 0.38842448592185974,
      "learning_rate": 1.64408e-05,
      "loss": 0.17919410705566408,
      "step": 4450
    },
    {
      "epoch": 0.18,
      "grad_norm": 5.577842712402344,
      "learning_rate": 1.64008e-05,
      "loss": 0.16509656906127929,
      "step": 4500
    },
    {
      "epoch": 0.182,
      "grad_norm": 0.8852806687355042,
      "learning_rate": 1.63608e-05,
      "loss": 0.1877592086791992,
      "step": 4550
    },
    {
      "epoch": 0.184,
      "grad_norm": 15.42672348022461,
      "learning_rate": 1.63208e-05,
      "loss": 0.2116946029663086,
      "step": 4600
    },
    {
      "epoch": 0.186,
      "grad_norm": 8.80597972869873,
      "learning_rate": 1.6280800000000002e-05,
      "loss": 0.23534061431884765,
      "step": 4650
    },
    {
      "epoch": 0.188,
      "grad_norm": 13.329631805419922,
      "learning_rate": 1.6240800000000002e-05,
      "loss": 0.1251411533355713,
      "step": 4700
    },
    {
      "epoch": 0.19,
      "grad_norm": 14.971902847290039,
      "learning_rate": 1.6200800000000003e-05,
      "loss": 0.14832990646362304,
      "step": 4750
    },
    {
      "epoch": 0.192,
      "grad_norm": 14.13593864440918,
      "learning_rate": 1.61608e-05,
      "loss": 0.24861865997314453,
      "step": 4800
    },
    {
      "epoch": 0.194,
      "grad_norm": 0.366933137178421,
      "learning_rate": 1.61208e-05,
      "loss": 0.18495708465576172,
      "step": 4850
    },
    {
      "epoch": 0.196,
      "grad_norm": 7.693119049072266,
      "learning_rate": 1.60808e-05,
      "loss": 0.21551385879516602,
      "step": 4900
    },
    {
      "epoch": 0.198,
      "grad_norm": 0.041087184101343155,
      "learning_rate": 1.60408e-05,
      "loss": 0.12896291732788087,
      "step": 4950
    },
    {
      "epoch": 0.2,
      "grad_norm": 9.4304780960083,
      "learning_rate": 1.60008e-05,
      "loss": 0.21764019012451172,
      "step": 5000
    },
    {
      "epoch": 0.202,
      "grad_norm": 8.064722061157227,
      "learning_rate": 1.59608e-05,
      "loss": 0.11800551414489746,
      "step": 5050
    },
    {
      "epoch": 0.204,
      "grad_norm": 0.07877881824970245,
      "learning_rate": 1.5920800000000002e-05,
      "loss": 0.15125751495361328,
      "step": 5100
    },
    {
      "epoch": 0.206,
      "grad_norm": 22.334705352783203,
      "learning_rate": 1.5880800000000002e-05,
      "loss": 0.17673826217651367,
      "step": 5150
    },
    {
      "epoch": 0.208,
      "grad_norm": 0.2898196280002594,
      "learning_rate": 1.58408e-05,
      "loss": 0.1905119514465332,
      "step": 5200
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.01975061558187008,
      "learning_rate": 1.58008e-05,
      "loss": 0.1066611099243164,
      "step": 5250
    },
    {
      "epoch": 0.212,
      "grad_norm": 24.179258346557617,
      "learning_rate": 1.57608e-05,
      "loss": 0.18198083877563476,
      "step": 5300
    },
    {
      "epoch": 0.214,
      "grad_norm": 1.6336249113082886,
      "learning_rate": 1.57208e-05,
      "loss": 0.2758743095397949,
      "step": 5350
    },
    {
      "epoch": 0.216,
      "grad_norm": 8.663317680358887,
      "learning_rate": 1.56808e-05,
      "loss": 0.20086391448974608,
      "step": 5400
    },
    {
      "epoch": 0.218,
      "grad_norm": 7.737632751464844,
      "learning_rate": 1.56408e-05,
      "loss": 0.17934751510620117,
      "step": 5450
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.059306614100933075,
      "learning_rate": 1.56008e-05,
      "loss": 0.15994617462158203,
      "step": 5500
    },
    {
      "epoch": 0.222,
      "grad_norm": 10.372227668762207,
      "learning_rate": 1.5560800000000002e-05,
      "loss": 0.2589321708679199,
      "step": 5550
    },
    {
      "epoch": 0.224,
      "grad_norm": 0.12722107768058777,
      "learning_rate": 1.55208e-05,
      "loss": 0.12671419143676757,
      "step": 5600
    },
    {
      "epoch": 0.226,
      "grad_norm": 0.07769157737493515,
      "learning_rate": 1.54808e-05,
      "loss": 0.22421806335449218,
      "step": 5650
    },
    {
      "epoch": 0.228,
      "grad_norm": 6.002908229827881,
      "learning_rate": 1.54408e-05,
      "loss": 0.20533050537109376,
      "step": 5700
    },
    {
      "epoch": 0.23,
      "grad_norm": 11.295633316040039,
      "learning_rate": 1.54008e-05,
      "loss": 0.15631924629211424,
      "step": 5750
    },
    {
      "epoch": 0.232,
      "grad_norm": 9.523880004882812,
      "learning_rate": 1.53608e-05,
      "loss": 0.16830223083496093,
      "step": 5800
    },
    {
      "epoch": 0.234,
      "grad_norm": 11.407903671264648,
      "learning_rate": 1.53208e-05,
      "loss": 0.1338908004760742,
      "step": 5850
    },
    {
      "epoch": 0.236,
      "grad_norm": 5.061319351196289,
      "learning_rate": 1.52808e-05,
      "loss": 0.1920609664916992,
      "step": 5900
    },
    {
      "epoch": 0.238,
      "grad_norm": 0.5557321906089783,
      "learning_rate": 1.5240800000000002e-05,
      "loss": 0.18075799942016602,
      "step": 5950
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.06803522258996964,
      "learning_rate": 1.5200800000000002e-05,
      "loss": 0.15308676719665526,
      "step": 6000
    },
    {
      "epoch": 0.242,
      "grad_norm": 0.06170915439724922,
      "learning_rate": 1.5160800000000002e-05,
      "loss": 0.22372461318969727,
      "step": 6050
    },
    {
      "epoch": 0.244,
      "grad_norm": 0.2655884921550751,
      "learning_rate": 1.5120800000000003e-05,
      "loss": 0.13783955574035645,
      "step": 6100
    },
    {
      "epoch": 0.246,
      "grad_norm": 5.50687313079834,
      "learning_rate": 1.5080800000000001e-05,
      "loss": 0.12385555267333985,
      "step": 6150
    },
    {
      "epoch": 0.248,
      "grad_norm": 8.281238555908203,
      "learning_rate": 1.5040800000000002e-05,
      "loss": 0.1974942970275879,
      "step": 6200
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.03790174797177315,
      "learning_rate": 1.5000800000000002e-05,
      "loss": 0.11833063125610352,
      "step": 6250
    },
    {
      "epoch": 0.252,
      "grad_norm": 20.29574203491211,
      "learning_rate": 1.4960800000000003e-05,
      "loss": 0.1271396255493164,
      "step": 6300
    },
    {
      "epoch": 0.254,
      "grad_norm": 7.198812484741211,
      "learning_rate": 1.4920800000000001e-05,
      "loss": 0.09624316215515137,
      "step": 6350
    },
    {
      "epoch": 0.256,
      "grad_norm": 0.3569142818450928,
      "learning_rate": 1.4880800000000002e-05,
      "loss": 0.16517568588256837,
      "step": 6400
    },
    {
      "epoch": 0.258,
      "grad_norm": 0.6688796281814575,
      "learning_rate": 1.4840800000000002e-05,
      "loss": 0.21474056243896483,
      "step": 6450
    },
    {
      "epoch": 0.26,
      "grad_norm": 12.030953407287598,
      "learning_rate": 1.4800800000000002e-05,
      "loss": 0.26082185745239256,
      "step": 6500
    },
    {
      "epoch": 0.262,
      "grad_norm": 6.039982318878174,
      "learning_rate": 1.4760800000000001e-05,
      "loss": 0.19516290664672853,
      "step": 6550
    },
    {
      "epoch": 0.264,
      "grad_norm": 6.211127281188965,
      "learning_rate": 1.4720800000000001e-05,
      "loss": 0.1832996940612793,
      "step": 6600
    },
    {
      "epoch": 0.266,
      "grad_norm": 0.062195878475904465,
      "learning_rate": 1.4680800000000002e-05,
      "loss": 0.19555942535400392,
      "step": 6650
    },
    {
      "epoch": 0.268,
      "grad_norm": 7.539119720458984,
      "learning_rate": 1.4640800000000002e-05,
      "loss": 0.1849063491821289,
      "step": 6700
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.08067595213651657,
      "learning_rate": 1.4600800000000001e-05,
      "loss": 0.1346157646179199,
      "step": 6750
    },
    {
      "epoch": 0.272,
      "grad_norm": 0.07290477305650711,
      "learning_rate": 1.4560800000000001e-05,
      "loss": 0.12556556701660157,
      "step": 6800
    },
    {
      "epoch": 0.274,
      "grad_norm": 2.5915169715881348,
      "learning_rate": 1.4520800000000002e-05,
      "loss": 0.1662125015258789,
      "step": 6850
    },
    {
      "epoch": 0.276,
      "grad_norm": 14.152509689331055,
      "learning_rate": 1.4480800000000002e-05,
      "loss": 0.16940114974975587,
      "step": 6900
    },
    {
      "epoch": 0.278,
      "grad_norm": 8.666594505310059,
      "learning_rate": 1.44408e-05,
      "loss": 0.31084264755249025,
      "step": 6950
    },
    {
      "epoch": 0.28,
      "grad_norm": 24.664409637451172,
      "learning_rate": 1.4400800000000001e-05,
      "loss": 0.18447645187377928,
      "step": 7000
    },
    {
      "epoch": 0.282,
      "grad_norm": 0.06242179498076439,
      "learning_rate": 1.4360800000000001e-05,
      "loss": 0.1173028564453125,
      "step": 7050
    },
    {
      "epoch": 0.284,
      "grad_norm": 14.639488220214844,
      "learning_rate": 1.4320800000000002e-05,
      "loss": 0.217026309967041,
      "step": 7100
    },
    {
      "epoch": 0.286,
      "grad_norm": 17.10145378112793,
      "learning_rate": 1.42808e-05,
      "loss": 0.15561762809753418,
      "step": 7150
    },
    {
      "epoch": 0.288,
      "grad_norm": 0.07383053749799728,
      "learning_rate": 1.4240800000000001e-05,
      "loss": 0.1627211570739746,
      "step": 7200
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.07369142770767212,
      "learning_rate": 1.4200800000000001e-05,
      "loss": 0.13237252235412597,
      "step": 7250
    },
    {
      "epoch": 0.292,
      "grad_norm": 0.2613524794578552,
      "learning_rate": 1.4160800000000002e-05,
      "loss": 0.22772333145141602,
      "step": 7300
    },
    {
      "epoch": 0.294,
      "grad_norm": 16.464685440063477,
      "learning_rate": 1.41208e-05,
      "loss": 0.22061344146728515,
      "step": 7350
    },
    {
      "epoch": 0.296,
      "grad_norm": 11.813129425048828,
      "learning_rate": 1.40808e-05,
      "loss": 0.1805463981628418,
      "step": 7400
    },
    {
      "epoch": 0.298,
      "grad_norm": 0.06117459386587143,
      "learning_rate": 1.4040800000000001e-05,
      "loss": 0.1061153507232666,
      "step": 7450
    },
    {
      "epoch": 0.3,
      "grad_norm": 19.623624801635742,
      "learning_rate": 1.4000800000000002e-05,
      "loss": 0.14298293113708496,
      "step": 7500
    },
    {
      "epoch": 0.302,
      "grad_norm": 0.05057153105735779,
      "learning_rate": 1.39608e-05,
      "loss": 0.15286622047424317,
      "step": 7550
    },
    {
      "epoch": 0.304,
      "grad_norm": 0.09686968475580215,
      "learning_rate": 1.39208e-05,
      "loss": 0.20174951553344728,
      "step": 7600
    },
    {
      "epoch": 0.306,
      "grad_norm": 0.8631461262702942,
      "learning_rate": 1.3880800000000001e-05,
      "loss": 0.1988484764099121,
      "step": 7650
    },
    {
      "epoch": 0.308,
      "grad_norm": 0.09728872776031494,
      "learning_rate": 1.3840800000000001e-05,
      "loss": 0.13559481620788574,
      "step": 7700
    },
    {
      "epoch": 0.31,
      "grad_norm": 12.986689567565918,
      "learning_rate": 1.38008e-05,
      "loss": 0.1574368667602539,
      "step": 7750
    },
    {
      "epoch": 0.312,
      "grad_norm": 2.2529501914978027,
      "learning_rate": 1.37608e-05,
      "loss": 0.1509781551361084,
      "step": 7800
    },
    {
      "epoch": 0.314,
      "grad_norm": 0.09868219494819641,
      "learning_rate": 1.37208e-05,
      "loss": 0.15355968475341797,
      "step": 7850
    },
    {
      "epoch": 0.316,
      "grad_norm": 0.07427074760198593,
      "learning_rate": 1.3680800000000001e-05,
      "loss": 0.17408506393432618,
      "step": 7900
    },
    {
      "epoch": 0.318,
      "grad_norm": 0.5739527940750122,
      "learning_rate": 1.36408e-05,
      "loss": 0.2491973876953125,
      "step": 7950
    },
    {
      "epoch": 0.32,
      "grad_norm": 24.730379104614258,
      "learning_rate": 1.36008e-05,
      "loss": 0.1830594825744629,
      "step": 8000
    },
    {
      "epoch": 0.322,
      "grad_norm": 0.10782930254936218,
      "learning_rate": 1.35608e-05,
      "loss": 0.13577595710754395,
      "step": 8050
    },
    {
      "epoch": 0.324,
      "grad_norm": 0.2386634200811386,
      "learning_rate": 1.3520800000000001e-05,
      "loss": 0.16804025650024415,
      "step": 8100
    },
    {
      "epoch": 0.326,
      "grad_norm": 10.123184204101562,
      "learning_rate": 1.34808e-05,
      "loss": 0.16917903900146483,
      "step": 8150
    },
    {
      "epoch": 0.328,
      "grad_norm": 0.16294167935848236,
      "learning_rate": 1.34408e-05,
      "loss": 0.17465234756469727,
      "step": 8200
    },
    {
      "epoch": 0.33,
      "grad_norm": 39.75899887084961,
      "learning_rate": 1.34008e-05,
      "loss": 0.15795327186584474,
      "step": 8250
    },
    {
      "epoch": 0.332,
      "grad_norm": 8.281211853027344,
      "learning_rate": 1.3360800000000001e-05,
      "loss": 0.14546823501586914,
      "step": 8300
    },
    {
      "epoch": 0.334,
      "grad_norm": 0.0639226958155632,
      "learning_rate": 1.33208e-05,
      "loss": 0.20355709075927733,
      "step": 8350
    },
    {
      "epoch": 0.336,
      "grad_norm": 15.95029354095459,
      "learning_rate": 1.32808e-05,
      "loss": 0.15310450553894042,
      "step": 8400
    },
    {
      "epoch": 0.338,
      "grad_norm": 7.233048915863037,
      "learning_rate": 1.32408e-05,
      "loss": 0.17235422134399414,
      "step": 8450
    },
    {
      "epoch": 0.34,
      "grad_norm": 5.895419597625732,
      "learning_rate": 1.32008e-05,
      "loss": 0.1676156997680664,
      "step": 8500
    },
    {
      "epoch": 0.342,
      "grad_norm": 0.20261621475219727,
      "learning_rate": 1.31608e-05,
      "loss": 0.1871505546569824,
      "step": 8550
    },
    {
      "epoch": 0.344,
      "grad_norm": 0.05166031792759895,
      "learning_rate": 1.31208e-05,
      "loss": 0.12575787544250489,
      "step": 8600
    },
    {
      "epoch": 0.346,
      "grad_norm": 0.02605290152132511,
      "learning_rate": 1.30808e-05,
      "loss": 0.13233407020568846,
      "step": 8650
    },
    {
      "epoch": 0.348,
      "grad_norm": 0.12827301025390625,
      "learning_rate": 1.30408e-05,
      "loss": 0.13830345153808593,
      "step": 8700
    },
    {
      "epoch": 0.35,
      "grad_norm": 18.827913284301758,
      "learning_rate": 1.30008e-05,
      "loss": 0.19249969482421875,
      "step": 8750
    },
    {
      "epoch": 0.352,
      "grad_norm": 14.71965503692627,
      "learning_rate": 1.29608e-05,
      "loss": 0.16511234283447265,
      "step": 8800
    },
    {
      "epoch": 0.354,
      "grad_norm": 22.57682228088379,
      "learning_rate": 1.29208e-05,
      "loss": 0.1788971519470215,
      "step": 8850
    },
    {
      "epoch": 0.356,
      "grad_norm": 0.03628847375512123,
      "learning_rate": 1.28808e-05,
      "loss": 0.16120567321777343,
      "step": 8900
    },
    {
      "epoch": 0.358,
      "grad_norm": 6.282408714294434,
      "learning_rate": 1.2840800000000002e-05,
      "loss": 0.13806346893310548,
      "step": 8950
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.022240620106458664,
      "learning_rate": 1.2800800000000003e-05,
      "loss": 0.09938738822937011,
      "step": 9000
    },
    {
      "epoch": 0.362,
      "grad_norm": 10.925312042236328,
      "learning_rate": 1.2760800000000002e-05,
      "loss": 0.18676286697387695,
      "step": 9050
    },
    {
      "epoch": 0.364,
      "grad_norm": 0.07459805905818939,
      "learning_rate": 1.2720800000000002e-05,
      "loss": 0.17870651245117186,
      "step": 9100
    },
    {
      "epoch": 0.366,
      "grad_norm": 0.31268858909606934,
      "learning_rate": 1.2680800000000002e-05,
      "loss": 0.20428718566894533,
      "step": 9150
    },
    {
      "epoch": 0.368,
      "grad_norm": 0.31801512837409973,
      "learning_rate": 1.2640800000000003e-05,
      "loss": 0.11071934700012206,
      "step": 9200
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.7205843925476074,
      "learning_rate": 1.2600800000000001e-05,
      "loss": 0.20645692825317383,
      "step": 9250
    },
    {
      "epoch": 0.372,
      "grad_norm": 0.28460824489593506,
      "learning_rate": 1.2560800000000002e-05,
      "loss": 0.19742626190185547,
      "step": 9300
    },
    {
      "epoch": 0.374,
      "grad_norm": 0.5021921992301941,
      "learning_rate": 1.2520800000000002e-05,
      "loss": 0.17958980560302734,
      "step": 9350
    },
    {
      "epoch": 0.376,
      "grad_norm": 10.447978019714355,
      "learning_rate": 1.2480800000000003e-05,
      "loss": 0.09262170791625976,
      "step": 9400
    },
    {
      "epoch": 0.378,
      "grad_norm": 0.019088955596089363,
      "learning_rate": 1.2440800000000001e-05,
      "loss": 0.21653221130371095,
      "step": 9450
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.6368762850761414,
      "learning_rate": 1.2400800000000002e-05,
      "loss": 0.1588750648498535,
      "step": 9500
    },
    {
      "epoch": 0.382,
      "grad_norm": 6.728066444396973,
      "learning_rate": 1.2360800000000002e-05,
      "loss": 0.1650766372680664,
      "step": 9550
    },
    {
      "epoch": 0.384,
      "grad_norm": 0.18742460012435913,
      "learning_rate": 1.2320800000000002e-05,
      "loss": 0.17686899185180663,
      "step": 9600
    },
    {
      "epoch": 0.386,
      "grad_norm": 0.04943887144327164,
      "learning_rate": 1.2280800000000001e-05,
      "loss": 0.13381051063537597,
      "step": 9650
    },
    {
      "epoch": 0.388,
      "grad_norm": 0.09313377737998962,
      "learning_rate": 1.2240800000000001e-05,
      "loss": 0.14566884994506835,
      "step": 9700
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.05024583265185356,
      "learning_rate": 1.2200800000000002e-05,
      "loss": 0.1535665512084961,
      "step": 9750
    },
    {
      "epoch": 0.392,
      "grad_norm": 14.360301971435547,
      "learning_rate": 1.2160800000000002e-05,
      "loss": 0.14173216819763185,
      "step": 9800
    },
    {
      "epoch": 0.394,
      "grad_norm": 32.80899429321289,
      "learning_rate": 1.2120800000000001e-05,
      "loss": 0.18303707122802734,
      "step": 9850
    },
    {
      "epoch": 0.396,
      "grad_norm": 0.08987875282764435,
      "learning_rate": 1.2080800000000001e-05,
      "loss": 0.0854570198059082,
      "step": 9900
    },
    {
      "epoch": 0.398,
      "grad_norm": 0.06881721317768097,
      "learning_rate": 1.2040800000000002e-05,
      "loss": 0.1895286750793457,
      "step": 9950
    },
    {
      "epoch": 0.4,
      "grad_norm": 24.04680824279785,
      "learning_rate": 1.2000800000000002e-05,
      "loss": 0.11732074737548828,
      "step": 10000
    },
    {
      "epoch": 0.402,
      "grad_norm": 0.032235145568847656,
      "learning_rate": 1.19608e-05,
      "loss": 0.1707831382751465,
      "step": 10050
    },
    {
      "epoch": 0.404,
      "grad_norm": 0.9781913757324219,
      "learning_rate": 1.1920800000000001e-05,
      "loss": 0.25010210037231445,
      "step": 10100
    },
    {
      "epoch": 0.406,
      "grad_norm": 0.1375514715909958,
      "learning_rate": 1.1880800000000002e-05,
      "loss": 0.08462498664855957,
      "step": 10150
    },
    {
      "epoch": 0.408,
      "grad_norm": 0.05732489377260208,
      "learning_rate": 1.1840800000000002e-05,
      "loss": 0.110672607421875,
      "step": 10200
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.006724492181092501,
      "learning_rate": 1.18008e-05,
      "loss": 0.10238731384277344,
      "step": 10250
    },
    {
      "epoch": 0.412,
      "grad_norm": 1.8414798974990845,
      "learning_rate": 1.1760800000000001e-05,
      "loss": 0.2411893844604492,
      "step": 10300
    },
    {
      "epoch": 0.414,
      "grad_norm": 2.049591302871704,
      "learning_rate": 1.1720800000000001e-05,
      "loss": 0.1776777458190918,
      "step": 10350
    },
    {
      "epoch": 0.416,
      "grad_norm": 0.05849715694785118,
      "learning_rate": 1.1680800000000002e-05,
      "loss": 0.16894254684448243,
      "step": 10400
    },
    {
      "epoch": 0.418,
      "grad_norm": 0.12969419360160828,
      "learning_rate": 1.16408e-05,
      "loss": 0.15973861694335936,
      "step": 10450
    },
    {
      "epoch": 0.42,
      "grad_norm": 13.479023933410645,
      "learning_rate": 1.16008e-05,
      "loss": 0.15099239349365234,
      "step": 10500
    },
    {
      "epoch": 0.422,
      "grad_norm": 16.492084503173828,
      "learning_rate": 1.1560800000000001e-05,
      "loss": 0.1467912483215332,
      "step": 10550
    },
    {
      "epoch": 0.424,
      "grad_norm": 0.04236295074224472,
      "learning_rate": 1.1520800000000002e-05,
      "loss": 0.11704168319702149,
      "step": 10600
    },
    {
      "epoch": 0.426,
      "grad_norm": 18.535097122192383,
      "learning_rate": 1.14808e-05,
      "loss": 0.11145913124084472,
      "step": 10650
    },
    {
      "epoch": 0.428,
      "grad_norm": 0.040115099400281906,
      "learning_rate": 1.14408e-05,
      "loss": 0.19019756317138672,
      "step": 10700
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.022011648863554,
      "learning_rate": 1.1400800000000001e-05,
      "loss": 0.14282565116882323,
      "step": 10750
    },
    {
      "epoch": 0.432,
      "grad_norm": 7.801797389984131,
      "learning_rate": 1.1360800000000001e-05,
      "loss": 0.13923556327819825,
      "step": 10800
    },
    {
      "epoch": 0.434,
      "grad_norm": 11.743692398071289,
      "learning_rate": 1.13208e-05,
      "loss": 0.16919418334960937,
      "step": 10850
    },
    {
      "epoch": 0.436,
      "grad_norm": 0.13934507966041565,
      "learning_rate": 1.12808e-05,
      "loss": 0.14577943801879883,
      "step": 10900
    },
    {
      "epoch": 0.438,
      "grad_norm": 0.2193204164505005,
      "learning_rate": 1.1240800000000001e-05,
      "loss": 0.16330738067626954,
      "step": 10950
    },
    {
      "epoch": 0.44,
      "grad_norm": 50.75122833251953,
      "learning_rate": 1.1200800000000001e-05,
      "loss": 0.12094855308532715,
      "step": 11000
    },
    {
      "epoch": 0.442,
      "grad_norm": 0.04871134087443352,
      "learning_rate": 1.11608e-05,
      "loss": 0.1843758010864258,
      "step": 11050
    },
    {
      "epoch": 0.444,
      "grad_norm": 0.1872527152299881,
      "learning_rate": 1.11208e-05,
      "loss": 0.17039012908935547,
      "step": 11100
    },
    {
      "epoch": 0.446,
      "grad_norm": 7.5459489822387695,
      "learning_rate": 1.10808e-05,
      "loss": 0.1290928077697754,
      "step": 11150
    },
    {
      "epoch": 0.448,
      "grad_norm": 0.14244940876960754,
      "learning_rate": 1.1040800000000001e-05,
      "loss": 0.14124368667602538,
      "step": 11200
    },
    {
      "epoch": 0.45,
      "grad_norm": 13.396466255187988,
      "learning_rate": 1.10008e-05,
      "loss": 0.12316137313842773,
      "step": 11250
    },
    {
      "epoch": 0.452,
      "grad_norm": 26.910001754760742,
      "learning_rate": 1.09608e-05,
      "loss": 0.18162281036376954,
      "step": 11300
    },
    {
      "epoch": 0.454,
      "grad_norm": 0.19778180122375488,
      "learning_rate": 1.09208e-05,
      "loss": 0.19509759902954102,
      "step": 11350
    },
    {
      "epoch": 0.456,
      "grad_norm": 0.08192073553800583,
      "learning_rate": 1.0880800000000001e-05,
      "loss": 0.1443161392211914,
      "step": 11400
    },
    {
      "epoch": 0.458,
      "grad_norm": 0.029572611674666405,
      "learning_rate": 1.08408e-05,
      "loss": 0.1013941764831543,
      "step": 11450
    },
    {
      "epoch": 0.46,
      "grad_norm": 13.272833824157715,
      "learning_rate": 1.08008e-05,
      "loss": 0.16927955627441407,
      "step": 11500
    },
    {
      "epoch": 0.462,
      "grad_norm": 6.0168938636779785,
      "learning_rate": 1.07608e-05,
      "loss": 0.21096160888671875,
      "step": 11550
    },
    {
      "epoch": 0.464,
      "grad_norm": 0.010683821514248848,
      "learning_rate": 1.07208e-05,
      "loss": 0.17375123977661133,
      "step": 11600
    },
    {
      "epoch": 0.466,
      "grad_norm": 0.37448248267173767,
      "learning_rate": 1.06808e-05,
      "loss": 0.1591738224029541,
      "step": 11650
    },
    {
      "epoch": 0.468,
      "grad_norm": 0.14435656368732452,
      "learning_rate": 1.06408e-05,
      "loss": 0.09290478706359863,
      "step": 11700
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.4739656150341034,
      "learning_rate": 1.06008e-05,
      "loss": 0.06862045288085937,
      "step": 11750
    },
    {
      "epoch": 0.472,
      "grad_norm": 0.12162305414676666,
      "learning_rate": 1.05608e-05,
      "loss": 0.18179792404174805,
      "step": 11800
    },
    {
      "epoch": 0.474,
      "grad_norm": 0.14713336527347565,
      "learning_rate": 1.05208e-05,
      "loss": 0.2038713264465332,
      "step": 11850
    },
    {
      "epoch": 0.476,
      "grad_norm": 11.189061164855957,
      "learning_rate": 1.04808e-05,
      "loss": 0.2005594253540039,
      "step": 11900
    },
    {
      "epoch": 0.478,
      "grad_norm": 0.3760840594768524,
      "learning_rate": 1.04408e-05,
      "loss": 0.15473504066467286,
      "step": 11950
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.05395309999585152,
      "learning_rate": 1.04008e-05,
      "loss": 0.19784692764282227,
      "step": 12000
    },
    {
      "epoch": 0.482,
      "grad_norm": 41.872283935546875,
      "learning_rate": 1.0360799999999999e-05,
      "loss": 0.12805102348327638,
      "step": 12050
    },
    {
      "epoch": 0.484,
      "grad_norm": 0.014957040548324585,
      "learning_rate": 1.0320800000000001e-05,
      "loss": 0.13617435455322266,
      "step": 12100
    },
    {
      "epoch": 0.486,
      "grad_norm": 0.025829631835222244,
      "learning_rate": 1.0280800000000002e-05,
      "loss": 0.14407746315002443,
      "step": 12150
    },
    {
      "epoch": 0.488,
      "grad_norm": 0.13114188611507416,
      "learning_rate": 1.0240800000000002e-05,
      "loss": 0.18288946151733398,
      "step": 12200
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.1819794923067093,
      "learning_rate": 1.0200800000000002e-05,
      "loss": 0.10217745780944824,
      "step": 12250
    },
    {
      "epoch": 0.492,
      "grad_norm": 26.391355514526367,
      "learning_rate": 1.0160800000000001e-05,
      "loss": 0.16239194869995116,
      "step": 12300
    },
    {
      "epoch": 0.494,
      "grad_norm": 0.9131886959075928,
      "learning_rate": 1.0120800000000001e-05,
      "loss": 0.17385313034057617,
      "step": 12350
    },
    {
      "epoch": 0.496,
      "grad_norm": 0.38438358902931213,
      "learning_rate": 1.0080800000000002e-05,
      "loss": 0.15840958595275878,
      "step": 12400
    },
    {
      "epoch": 0.498,
      "grad_norm": 0.04351571947336197,
      "learning_rate": 1.0040800000000002e-05,
      "loss": 0.18575971603393554,
      "step": 12450
    },
    {
      "epoch": 0.5,
      "grad_norm": 9.472280502319336,
      "learning_rate": 1.0000800000000001e-05,
      "loss": 0.12309938430786133,
      "step": 12500
    },
    {
      "epoch": 0.502,
      "grad_norm": 0.03180578723549843,
      "learning_rate": 9.960800000000001e-06,
      "loss": 0.18217552185058594,
      "step": 12550
    },
    {
      "epoch": 0.504,
      "grad_norm": 0.13711553812026978,
      "learning_rate": 9.9208e-06,
      "loss": 0.1515315818786621,
      "step": 12600
    },
    {
      "epoch": 0.506,
      "grad_norm": 16.109148025512695,
      "learning_rate": 9.8808e-06,
      "loss": 0.1827664566040039,
      "step": 12650
    },
    {
      "epoch": 0.508,
      "grad_norm": 12.331269264221191,
      "learning_rate": 9.8408e-06,
      "loss": 0.1405557632446289,
      "step": 12700
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.017596442252397537,
      "learning_rate": 9.800800000000001e-06,
      "loss": 0.12729104042053221,
      "step": 12750
    },
    {
      "epoch": 0.512,
      "grad_norm": 0.41488850116729736,
      "learning_rate": 9.7608e-06,
      "loss": 0.1690843391418457,
      "step": 12800
    },
    {
      "epoch": 0.514,
      "grad_norm": 0.24797454476356506,
      "learning_rate": 9.720800000000002e-06,
      "loss": 0.13154254913330077,
      "step": 12850
    },
    {
      "epoch": 0.516,
      "grad_norm": 0.046890806406736374,
      "learning_rate": 9.6808e-06,
      "loss": 0.15792678833007812,
      "step": 12900
    },
    {
      "epoch": 0.518,
      "grad_norm": 8.560090065002441,
      "learning_rate": 9.640800000000001e-06,
      "loss": 0.1875765609741211,
      "step": 12950
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.06354393064975739,
      "learning_rate": 9.600800000000001e-06,
      "loss": 0.10233142852783203,
      "step": 13000
    },
    {
      "epoch": 0.522,
      "grad_norm": 7.489167213439941,
      "learning_rate": 9.560800000000002e-06,
      "loss": 0.13421167373657228,
      "step": 13050
    },
    {
      "epoch": 0.524,
      "grad_norm": 0.02268042042851448,
      "learning_rate": 9.5208e-06,
      "loss": 0.08676502227783203,
      "step": 13100
    },
    {
      "epoch": 0.526,
      "grad_norm": 0.31177204847335815,
      "learning_rate": 9.4808e-06,
      "loss": 0.155321044921875,
      "step": 13150
    },
    {
      "epoch": 0.528,
      "grad_norm": 9.87078857421875,
      "learning_rate": 9.440800000000001e-06,
      "loss": 0.13583587646484374,
      "step": 13200
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.18148168921470642,
      "learning_rate": 9.400800000000002e-06,
      "loss": 0.14210753440856932,
      "step": 13250
    },
    {
      "epoch": 0.532,
      "grad_norm": 0.3721024990081787,
      "learning_rate": 9.3608e-06,
      "loss": 0.1532611846923828,
      "step": 13300
    },
    {
      "epoch": 0.534,
      "grad_norm": 0.07851376384496689,
      "learning_rate": 9.3208e-06,
      "loss": 0.14660107612609863,
      "step": 13350
    },
    {
      "epoch": 0.536,
      "grad_norm": 0.13315947353839874,
      "learning_rate": 9.280800000000001e-06,
      "loss": 0.18198398590087891,
      "step": 13400
    },
    {
      "epoch": 0.538,
      "grad_norm": 0.9261868596076965,
      "learning_rate": 9.240800000000001e-06,
      "loss": 0.11773423194885253,
      "step": 13450
    },
    {
      "epoch": 0.54,
      "grad_norm": 15.784507751464844,
      "learning_rate": 9.2008e-06,
      "loss": 0.12832396507263183,
      "step": 13500
    },
    {
      "epoch": 0.542,
      "grad_norm": 0.3058621883392334,
      "learning_rate": 9.1608e-06,
      "loss": 0.10319833755493164,
      "step": 13550
    },
    {
      "epoch": 0.544,
      "grad_norm": 29.619136810302734,
      "learning_rate": 9.1208e-06,
      "loss": 0.10777753829956055,
      "step": 13600
    },
    {
      "epoch": 0.546,
      "grad_norm": 0.19285796582698822,
      "learning_rate": 9.080800000000001e-06,
      "loss": 0.1268513298034668,
      "step": 13650
    },
    {
      "epoch": 0.548,
      "grad_norm": 0.11767620593309402,
      "learning_rate": 9.0408e-06,
      "loss": 0.1488707447052002,
      "step": 13700
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.26535317301750183,
      "learning_rate": 9.0008e-06,
      "loss": 0.1076426601409912,
      "step": 13750
    },
    {
      "epoch": 0.552,
      "grad_norm": 0.19598603248596191,
      "learning_rate": 8.9608e-06,
      "loss": 0.19134098052978515,
      "step": 13800
    },
    {
      "epoch": 0.554,
      "grad_norm": 0.057637207210063934,
      "learning_rate": 8.920800000000001e-06,
      "loss": 0.13915302276611327,
      "step": 13850
    },
    {
      "epoch": 0.556,
      "grad_norm": 0.6144135594367981,
      "learning_rate": 8.8808e-06,
      "loss": 0.07390818119049072,
      "step": 13900
    },
    {
      "epoch": 0.558,
      "grad_norm": 0.030065303668379784,
      "learning_rate": 8.8408e-06,
      "loss": 0.10246053695678711,
      "step": 13950
    },
    {
      "epoch": 0.56,
      "grad_norm": 8.843058586120605,
      "learning_rate": 8.8008e-06,
      "loss": 0.15019286155700684,
      "step": 14000
    },
    {
      "epoch": 0.562,
      "grad_norm": 25.967588424682617,
      "learning_rate": 8.760800000000001e-06,
      "loss": 0.10331357955932617,
      "step": 14050
    },
    {
      "epoch": 0.564,
      "grad_norm": 68.0931167602539,
      "learning_rate": 8.7208e-06,
      "loss": 0.1527685070037842,
      "step": 14100
    },
    {
      "epoch": 0.566,
      "grad_norm": 0.04804510250687599,
      "learning_rate": 8.6808e-06,
      "loss": 0.13270672798156738,
      "step": 14150
    },
    {
      "epoch": 0.568,
      "grad_norm": 0.20429551601409912,
      "learning_rate": 8.6408e-06,
      "loss": 0.1667561149597168,
      "step": 14200
    },
    {
      "epoch": 0.57,
      "grad_norm": 4.47802734375,
      "learning_rate": 8.6008e-06,
      "loss": 0.17403480529785156,
      "step": 14250
    },
    {
      "epoch": 0.572,
      "grad_norm": 14.916257858276367,
      "learning_rate": 8.5608e-06,
      "loss": 0.22609378814697265,
      "step": 14300
    },
    {
      "epoch": 0.574,
      "grad_norm": 0.027055250480771065,
      "learning_rate": 8.5208e-06,
      "loss": 0.05493693828582764,
      "step": 14350
    },
    {
      "epoch": 0.576,
      "grad_norm": 0.1267612874507904,
      "learning_rate": 8.4808e-06,
      "loss": 0.16422033309936523,
      "step": 14400
    },
    {
      "epoch": 0.578,
      "grad_norm": 1.7596611976623535,
      "learning_rate": 8.4408e-06,
      "loss": 0.13485355377197267,
      "step": 14450
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.08043893426656723,
      "learning_rate": 8.400800000000001e-06,
      "loss": 0.1930183219909668,
      "step": 14500
    },
    {
      "epoch": 0.582,
      "grad_norm": 8.363164901733398,
      "learning_rate": 8.360800000000001e-06,
      "loss": 0.19364152908325194,
      "step": 14550
    },
    {
      "epoch": 0.584,
      "grad_norm": 3.210613965988159,
      "learning_rate": 8.320800000000002e-06,
      "loss": 0.14476764678955079,
      "step": 14600
    },
    {
      "epoch": 0.586,
      "grad_norm": 30.877315521240234,
      "learning_rate": 8.2808e-06,
      "loss": 0.14293750762939453,
      "step": 14650
    },
    {
      "epoch": 0.588,
      "grad_norm": 0.07621613889932632,
      "learning_rate": 8.2408e-06,
      "loss": 0.13100112915039064,
      "step": 14700
    },
    {
      "epoch": 0.59,
      "grad_norm": 8.771356582641602,
      "learning_rate": 8.200800000000001e-06,
      "loss": 0.18853614807128907,
      "step": 14750
    },
    {
      "epoch": 0.592,
      "grad_norm": 0.011849743314087391,
      "learning_rate": 8.160800000000002e-06,
      "loss": 0.16640233993530273,
      "step": 14800
    },
    {
      "epoch": 0.594,
      "grad_norm": 31.24152374267578,
      "learning_rate": 8.1208e-06,
      "loss": 0.2165511131286621,
      "step": 14850
    },
    {
      "epoch": 0.596,
      "grad_norm": 0.044626906514167786,
      "learning_rate": 8.0808e-06,
      "loss": 0.14481110572814943,
      "step": 14900
    },
    {
      "epoch": 0.598,
      "grad_norm": 27.899433135986328,
      "learning_rate": 8.040800000000001e-06,
      "loss": 0.15837495803833007,
      "step": 14950
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.089696004986763,
      "learning_rate": 8.000800000000001e-06,
      "loss": 0.17858871459960937,
      "step": 15000
    },
    {
      "epoch": 0.602,
      "grad_norm": 0.6893996596336365,
      "learning_rate": 7.9608e-06,
      "loss": 0.19400896072387697,
      "step": 15050
    },
    {
      "epoch": 0.604,
      "grad_norm": 1.0598124265670776,
      "learning_rate": 7.9208e-06,
      "loss": 0.1639103889465332,
      "step": 15100
    },
    {
      "epoch": 0.606,
      "grad_norm": 9.291556358337402,
      "learning_rate": 7.8808e-06,
      "loss": 0.06561429977416992,
      "step": 15150
    },
    {
      "epoch": 0.608,
      "grad_norm": 5.036367893218994,
      "learning_rate": 7.840800000000001e-06,
      "loss": 0.200541934967041,
      "step": 15200
    },
    {
      "epoch": 0.61,
      "grad_norm": 8.05603313446045,
      "learning_rate": 7.8008e-06,
      "loss": 0.1296055221557617,
      "step": 15250
    },
    {
      "epoch": 0.612,
      "grad_norm": 0.04879958927631378,
      "learning_rate": 7.7608e-06,
      "loss": 0.16063467025756836,
      "step": 15300
    },
    {
      "epoch": 0.614,
      "grad_norm": 0.09273570775985718,
      "learning_rate": 7.7208e-06,
      "loss": 0.16972667694091798,
      "step": 15350
    },
    {
      "epoch": 0.616,
      "grad_norm": 0.17917855083942413,
      "learning_rate": 7.680800000000001e-06,
      "loss": 0.175670108795166,
      "step": 15400
    },
    {
      "epoch": 0.618,
      "grad_norm": 0.058819711208343506,
      "learning_rate": 7.6408e-06,
      "loss": 0.13882492065429688,
      "step": 15450
    },
    {
      "epoch": 0.62,
      "grad_norm": 9.387434005737305,
      "learning_rate": 7.6008e-06,
      "loss": 0.14415757179260255,
      "step": 15500
    },
    {
      "epoch": 0.622,
      "grad_norm": 0.1801092028617859,
      "learning_rate": 7.5608000000000005e-06,
      "loss": 0.15250371932983398,
      "step": 15550
    },
    {
      "epoch": 0.624,
      "grad_norm": 0.02734590321779251,
      "learning_rate": 7.5208e-06,
      "loss": 0.14486839294433593,
      "step": 15600
    },
    {
      "epoch": 0.626,
      "grad_norm": 0.04798320680856705,
      "learning_rate": 7.4808000000000004e-06,
      "loss": 0.20223508834838866,
      "step": 15650
    },
    {
      "epoch": 0.628,
      "grad_norm": 0.13141420483589172,
      "learning_rate": 7.4408e-06,
      "loss": 0.16757883071899415,
      "step": 15700
    },
    {
      "epoch": 0.63,
      "grad_norm": 22.260955810546875,
      "learning_rate": 7.4008e-06,
      "loss": 0.2697576904296875,
      "step": 15750
    },
    {
      "epoch": 0.632,
      "grad_norm": 0.05173996835947037,
      "learning_rate": 7.3608e-06,
      "loss": 0.16161592483520507,
      "step": 15800
    },
    {
      "epoch": 0.634,
      "grad_norm": 0.019509166479110718,
      "learning_rate": 7.3208e-06,
      "loss": 0.1608454704284668,
      "step": 15850
    },
    {
      "epoch": 0.636,
      "grad_norm": 0.18850013613700867,
      "learning_rate": 7.2808e-06,
      "loss": 0.19621509552001953,
      "step": 15900
    },
    {
      "epoch": 0.638,
      "grad_norm": 33.78840255737305,
      "learning_rate": 7.2408e-06,
      "loss": 0.0796436071395874,
      "step": 15950
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.1004757359623909,
      "learning_rate": 7.2008000000000014e-06,
      "loss": 0.13266801834106445,
      "step": 16000
    },
    {
      "epoch": 0.642,
      "grad_norm": 0.9109498858451843,
      "learning_rate": 7.160800000000001e-06,
      "loss": 0.10310195922851563,
      "step": 16050
    },
    {
      "epoch": 0.644,
      "grad_norm": 30.488298416137695,
      "learning_rate": 7.120800000000001e-06,
      "loss": 0.18280014038085937,
      "step": 16100
    },
    {
      "epoch": 0.646,
      "grad_norm": 0.07993347197771072,
      "learning_rate": 7.080800000000001e-06,
      "loss": 0.20172979354858397,
      "step": 16150
    },
    {
      "epoch": 0.648,
      "grad_norm": 0.04430233687162399,
      "learning_rate": 7.040800000000001e-06,
      "loss": 0.11445634841918945,
      "step": 16200
    },
    {
      "epoch": 0.65,
      "grad_norm": 34.11184310913086,
      "learning_rate": 7.000800000000001e-06,
      "loss": 0.19670297622680663,
      "step": 16250
    },
    {
      "epoch": 0.652,
      "grad_norm": 0.13413052260875702,
      "learning_rate": 6.960800000000001e-06,
      "loss": 0.12840126037597657,
      "step": 16300
    },
    {
      "epoch": 0.654,
      "grad_norm": 0.04083918035030365,
      "learning_rate": 6.920800000000001e-06,
      "loss": 0.08659589767456055,
      "step": 16350
    },
    {
      "epoch": 0.656,
      "grad_norm": 0.7220348119735718,
      "learning_rate": 6.880800000000001e-06,
      "loss": 0.10897644996643066,
      "step": 16400
    },
    {
      "epoch": 0.658,
      "grad_norm": 6.030401229858398,
      "learning_rate": 6.840800000000001e-06,
      "loss": 0.12100193023681641,
      "step": 16450
    },
    {
      "epoch": 0.66,
      "grad_norm": 10.489424705505371,
      "learning_rate": 6.800800000000001e-06,
      "loss": 0.20717691421508788,
      "step": 16500
    },
    {
      "epoch": 0.662,
      "grad_norm": 0.13369742035865784,
      "learning_rate": 6.7608000000000006e-06,
      "loss": 0.1579364776611328,
      "step": 16550
    },
    {
      "epoch": 0.664,
      "grad_norm": 0.024606600403785706,
      "learning_rate": 6.720800000000001e-06,
      "loss": 0.11722184181213378,
      "step": 16600
    },
    {
      "epoch": 0.666,
      "grad_norm": 0.022865843027830124,
      "learning_rate": 6.6808000000000005e-06,
      "loss": 0.12860185623168946,
      "step": 16650
    },
    {
      "epoch": 0.668,
      "grad_norm": 2.760084390640259,
      "learning_rate": 6.640800000000001e-06,
      "loss": 0.1376137065887451,
      "step": 16700
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.2208554446697235,
      "learning_rate": 6.6008e-06,
      "loss": 0.18091594696044921,
      "step": 16750
    },
    {
      "epoch": 0.672,
      "grad_norm": 0.39420056343078613,
      "learning_rate": 6.560800000000001e-06,
      "loss": 0.17233999252319335,
      "step": 16800
    },
    {
      "epoch": 0.674,
      "grad_norm": 0.4720032811164856,
      "learning_rate": 6.5208e-06,
      "loss": 0.14419509887695312,
      "step": 16850
    },
    {
      "epoch": 0.676,
      "grad_norm": 9.044577598571777,
      "learning_rate": 6.480800000000001e-06,
      "loss": 0.14434611320495605,
      "step": 16900
    },
    {
      "epoch": 0.678,
      "grad_norm": 0.048100437968969345,
      "learning_rate": 6.4408e-06,
      "loss": 0.12389079093933106,
      "step": 16950
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.04083187133073807,
      "learning_rate": 6.400800000000001e-06,
      "loss": 0.13805562019348144,
      "step": 17000
    },
    {
      "epoch": 0.682,
      "grad_norm": 8.014429092407227,
      "learning_rate": 6.3608e-06,
      "loss": 0.16356418609619142,
      "step": 17050
    },
    {
      "epoch": 0.684,
      "grad_norm": 3.4927141666412354,
      "learning_rate": 6.3208000000000005e-06,
      "loss": 0.12812251091003418,
      "step": 17100
    },
    {
      "epoch": 0.686,
      "grad_norm": 4.779284954071045,
      "learning_rate": 6.2808e-06,
      "loss": 0.11192036628723144,
      "step": 17150
    },
    {
      "epoch": 0.688,
      "grad_norm": 0.07128886878490448,
      "learning_rate": 6.2408000000000005e-06,
      "loss": 0.1485677719116211,
      "step": 17200
    },
    {
      "epoch": 0.69,
      "grad_norm": 6.508982181549072,
      "learning_rate": 6.2008e-06,
      "loss": 0.11989561080932618,
      "step": 17250
    },
    {
      "epoch": 0.692,
      "grad_norm": 0.053291257470846176,
      "learning_rate": 6.1608e-06,
      "loss": 0.13779035568237305,
      "step": 17300
    },
    {
      "epoch": 0.694,
      "grad_norm": 11.224435806274414,
      "learning_rate": 6.1208e-06,
      "loss": 0.15274483680725098,
      "step": 17350
    },
    {
      "epoch": 0.696,
      "grad_norm": 0.013611423783004284,
      "learning_rate": 6.0808e-06,
      "loss": 0.11821489334106446,
      "step": 17400
    },
    {
      "epoch": 0.698,
      "grad_norm": 0.22043249011039734,
      "learning_rate": 6.0408e-06,
      "loss": 0.16203546524047852,
      "step": 17450
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.01377790980041027,
      "learning_rate": 6.0008e-06,
      "loss": 0.11471404075622559,
      "step": 17500
    },
    {
      "epoch": 0.702,
      "grad_norm": 10.190119743347168,
      "learning_rate": 5.9608000000000014e-06,
      "loss": 0.1957706069946289,
      "step": 17550
    },
    {
      "epoch": 0.704,
      "grad_norm": 0.0363890714943409,
      "learning_rate": 5.920800000000001e-06,
      "loss": 0.1768893814086914,
      "step": 17600
    },
    {
      "epoch": 0.706,
      "grad_norm": 24.288860321044922,
      "learning_rate": 5.880800000000001e-06,
      "loss": 0.18235038757324218,
      "step": 17650
    },
    {
      "epoch": 0.708,
      "grad_norm": 0.14746057987213135,
      "learning_rate": 5.840800000000001e-06,
      "loss": 0.150990047454834,
      "step": 17700
    },
    {
      "epoch": 0.71,
      "grad_norm": 14.469017028808594,
      "learning_rate": 5.800800000000001e-06,
      "loss": 0.12935912132263183,
      "step": 17750
    },
    {
      "epoch": 0.712,
      "grad_norm": 0.04804307594895363,
      "learning_rate": 5.760800000000001e-06,
      "loss": 0.19832332611083983,
      "step": 17800
    },
    {
      "epoch": 0.714,
      "grad_norm": 0.0456792376935482,
      "learning_rate": 5.720800000000001e-06,
      "loss": 0.1336548900604248,
      "step": 17850
    },
    {
      "epoch": 0.716,
      "grad_norm": 0.48612433671951294,
      "learning_rate": 5.680800000000001e-06,
      "loss": 0.14141677856445312,
      "step": 17900
    },
    {
      "epoch": 0.718,
      "grad_norm": 11.536809921264648,
      "learning_rate": 5.640800000000001e-06,
      "loss": 0.1634654998779297,
      "step": 17950
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.6444218158721924,
      "learning_rate": 5.600800000000001e-06,
      "loss": 0.09863452911376953,
      "step": 18000
    },
    {
      "epoch": 0.722,
      "grad_norm": 3.0899252891540527,
      "learning_rate": 5.560800000000001e-06,
      "loss": 0.20350168228149415,
      "step": 18050
    },
    {
      "epoch": 0.724,
      "grad_norm": 1.0313482284545898,
      "learning_rate": 5.5208000000000006e-06,
      "loss": 0.10580828666687012,
      "step": 18100
    },
    {
      "epoch": 0.726,
      "grad_norm": 0.07061612606048584,
      "learning_rate": 5.480800000000001e-06,
      "loss": 0.14656267166137696,
      "step": 18150
    },
    {
      "epoch": 0.728,
      "grad_norm": 0.08826693892478943,
      "learning_rate": 5.4408000000000005e-06,
      "loss": 0.09948638916015624,
      "step": 18200
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.08812542259693146,
      "learning_rate": 5.400800000000001e-06,
      "loss": 0.06126020431518555,
      "step": 18250
    },
    {
      "epoch": 0.732,
      "grad_norm": 10.013400077819824,
      "learning_rate": 5.3608e-06,
      "loss": 0.19192630767822266,
      "step": 18300
    },
    {
      "epoch": 0.734,
      "grad_norm": 0.0326751209795475,
      "learning_rate": 5.320800000000001e-06,
      "loss": 0.24153511047363282,
      "step": 18350
    },
    {
      "epoch": 0.736,
      "grad_norm": 0.1624632626771927,
      "learning_rate": 5.2808e-06,
      "loss": 0.13292400360107423,
      "step": 18400
    },
    {
      "epoch": 0.738,
      "grad_norm": 0.09121554344892502,
      "learning_rate": 5.240800000000001e-06,
      "loss": 0.03179227352142334,
      "step": 18450
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.39391520619392395,
      "learning_rate": 5.2008e-06,
      "loss": 0.24477937698364258,
      "step": 18500
    },
    {
      "epoch": 0.742,
      "grad_norm": 7.206015110015869,
      "learning_rate": 5.160800000000001e-06,
      "loss": 0.16200912475585938,
      "step": 18550
    },
    {
      "epoch": 0.744,
      "grad_norm": 0.240728959441185,
      "learning_rate": 5.1208e-06,
      "loss": 0.14068864822387694,
      "step": 18600
    },
    {
      "epoch": 0.746,
      "grad_norm": 6.565073490142822,
      "learning_rate": 5.0808000000000006e-06,
      "loss": 0.1612110137939453,
      "step": 18650
    },
    {
      "epoch": 0.748,
      "grad_norm": 6.233607769012451,
      "learning_rate": 5.0408e-06,
      "loss": 0.11482625007629395,
      "step": 18700
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.01737244240939617,
      "learning_rate": 5.0008000000000005e-06,
      "loss": 0.12553359031677247,
      "step": 18750
    },
    {
      "epoch": 0.752,
      "grad_norm": 0.13024267554283142,
      "learning_rate": 4.960800000000001e-06,
      "loss": 0.11858512878417969,
      "step": 18800
    },
    {
      "epoch": 0.754,
      "grad_norm": 10.951175689697266,
      "learning_rate": 4.9208e-06,
      "loss": 0.1227372169494629,
      "step": 18850
    },
    {
      "epoch": 0.756,
      "grad_norm": 0.09745997935533524,
      "learning_rate": 4.880800000000001e-06,
      "loss": 0.13621701240539552,
      "step": 18900
    },
    {
      "epoch": 0.758,
      "grad_norm": 0.08544236421585083,
      "learning_rate": 4.8408e-06,
      "loss": 0.1465471363067627,
      "step": 18950
    },
    {
      "epoch": 0.76,
      "grad_norm": 5.539083003997803,
      "learning_rate": 4.800800000000001e-06,
      "loss": 0.1719173812866211,
      "step": 19000
    },
    {
      "epoch": 0.762,
      "grad_norm": 0.02876928634941578,
      "learning_rate": 4.7608e-06,
      "loss": 0.12995018005371095,
      "step": 19050
    },
    {
      "epoch": 0.764,
      "grad_norm": 0.06358331441879272,
      "learning_rate": 4.720800000000001e-06,
      "loss": 0.14019410133361818,
      "step": 19100
    },
    {
      "epoch": 0.766,
      "grad_norm": 0.044791098684072495,
      "learning_rate": 4.6808e-06,
      "loss": 0.08407466888427734,
      "step": 19150
    },
    {
      "epoch": 0.768,
      "grad_norm": 0.7922179102897644,
      "learning_rate": 4.6408000000000005e-06,
      "loss": 0.1949414825439453,
      "step": 19200
    },
    {
      "epoch": 0.77,
      "grad_norm": 13.565481185913086,
      "learning_rate": 4.6008e-06,
      "loss": 0.15238097190856933,
      "step": 19250
    },
    {
      "epoch": 0.772,
      "grad_norm": 0.08934345841407776,
      "learning_rate": 4.5608000000000004e-06,
      "loss": 0.127440185546875,
      "step": 19300
    },
    {
      "epoch": 0.774,
      "grad_norm": 0.041985128074884415,
      "learning_rate": 4.5208e-06,
      "loss": 0.13784772872924805,
      "step": 19350
    },
    {
      "epoch": 0.776,
      "grad_norm": 0.6219421029090881,
      "learning_rate": 4.4808e-06,
      "loss": 0.1913344955444336,
      "step": 19400
    },
    {
      "epoch": 0.778,
      "grad_norm": 32.70894241333008,
      "learning_rate": 4.4408e-06,
      "loss": 0.1494991397857666,
      "step": 19450
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.3247070014476776,
      "learning_rate": 4.4008e-06,
      "loss": 0.08796467781066894,
      "step": 19500
    },
    {
      "epoch": 0.782,
      "grad_norm": 8.657400131225586,
      "learning_rate": 4.360800000000001e-06,
      "loss": 0.15367761611938477,
      "step": 19550
    },
    {
      "epoch": 0.784,
      "grad_norm": 4.554119110107422,
      "learning_rate": 4.3208e-06,
      "loss": 0.07115239143371582,
      "step": 19600
    },
    {
      "epoch": 0.786,
      "grad_norm": 7.511999130249023,
      "learning_rate": 4.280800000000001e-06,
      "loss": 0.16841482162475585,
      "step": 19650
    },
    {
      "epoch": 0.788,
      "grad_norm": 0.1553499847650528,
      "learning_rate": 4.2408e-06,
      "loss": 0.11435408592224121,
      "step": 19700
    },
    {
      "epoch": 0.79,
      "grad_norm": 24.406667709350586,
      "learning_rate": 4.2008000000000005e-06,
      "loss": 0.0652359676361084,
      "step": 19750
    },
    {
      "epoch": 0.792,
      "grad_norm": 0.07102315127849579,
      "learning_rate": 4.1608e-06,
      "loss": 0.16768878936767578,
      "step": 19800
    },
    {
      "epoch": 0.794,
      "grad_norm": 0.12440759688615799,
      "learning_rate": 4.1208000000000004e-06,
      "loss": 0.08290520668029785,
      "step": 19850
    },
    {
      "epoch": 0.796,
      "grad_norm": 0.9625349044799805,
      "learning_rate": 4.0808e-06,
      "loss": 0.1791107177734375,
      "step": 19900
    },
    {
      "epoch": 0.798,
      "grad_norm": 0.7564820647239685,
      "learning_rate": 4.0408e-06,
      "loss": 0.21983213424682618,
      "step": 19950
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.10856619477272034,
      "learning_rate": 4.0008e-06,
      "loss": 0.17080350875854491,
      "step": 20000
    },
    {
      "epoch": 0.802,
      "grad_norm": 1.9234414100646973,
      "learning_rate": 3.9608e-06,
      "loss": 0.10339686393737793,
      "step": 20050
    },
    {
      "epoch": 0.804,
      "grad_norm": 1.549933671951294,
      "learning_rate": 3.9208e-06,
      "loss": 0.17240135192871095,
      "step": 20100
    },
    {
      "epoch": 0.806,
      "grad_norm": 0.05972183868288994,
      "learning_rate": 3.8808e-06,
      "loss": 0.13958270072937012,
      "step": 20150
    },
    {
      "epoch": 0.808,
      "grad_norm": 0.7249744534492493,
      "learning_rate": 3.8408e-06,
      "loss": 0.19265668869018554,
      "step": 20200
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.2163623869419098,
      "learning_rate": 3.8008e-06,
      "loss": 0.128906946182251,
      "step": 20250
    },
    {
      "epoch": 0.812,
      "grad_norm": 13.159257888793945,
      "learning_rate": 3.7608000000000005e-06,
      "loss": 0.17278108596801758,
      "step": 20300
    },
    {
      "epoch": 0.814,
      "grad_norm": 0.12733148038387299,
      "learning_rate": 3.7208000000000004e-06,
      "loss": 0.09427557945251465,
      "step": 20350
    },
    {
      "epoch": 0.816,
      "grad_norm": 0.05474287271499634,
      "learning_rate": 3.6808000000000004e-06,
      "loss": 0.0973118019104004,
      "step": 20400
    },
    {
      "epoch": 0.818,
      "grad_norm": 4.211671829223633,
      "learning_rate": 3.6408000000000004e-06,
      "loss": 0.1658220672607422,
      "step": 20450
    },
    {
      "epoch": 0.82,
      "grad_norm": 21.973270416259766,
      "learning_rate": 3.6008000000000003e-06,
      "loss": 0.13395997047424316,
      "step": 20500
    },
    {
      "epoch": 0.822,
      "grad_norm": 0.018776731565594673,
      "learning_rate": 3.5608000000000003e-06,
      "loss": 0.1330439853668213,
      "step": 20550
    },
    {
      "epoch": 0.824,
      "grad_norm": 0.03892812505364418,
      "learning_rate": 3.5208000000000002e-06,
      "loss": 0.11704468727111816,
      "step": 20600
    },
    {
      "epoch": 0.826,
      "grad_norm": 22.69905662536621,
      "learning_rate": 3.4808e-06,
      "loss": 0.1295143508911133,
      "step": 20650
    },
    {
      "epoch": 0.828,
      "grad_norm": 11.8572359085083,
      "learning_rate": 3.4408e-06,
      "loss": 0.1472736644744873,
      "step": 20700
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.4196600615978241,
      "learning_rate": 3.4008e-06,
      "loss": 0.20377208709716796,
      "step": 20750
    },
    {
      "epoch": 0.832,
      "grad_norm": 6.444173812866211,
      "learning_rate": 3.3608e-06,
      "loss": 0.07659632205963135,
      "step": 20800
    },
    {
      "epoch": 0.834,
      "grad_norm": 0.018668001517653465,
      "learning_rate": 3.3208e-06,
      "loss": 0.11646122932434082,
      "step": 20850
    },
    {
      "epoch": 0.836,
      "grad_norm": 0.2777096927165985,
      "learning_rate": 3.2808e-06,
      "loss": 0.14891998291015626,
      "step": 20900
    },
    {
      "epoch": 0.838,
      "grad_norm": 0.1397809088230133,
      "learning_rate": 3.2408e-06,
      "loss": 0.17330978393554688,
      "step": 20950
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.330282062292099,
      "learning_rate": 3.2008e-06,
      "loss": 0.10599610328674317,
      "step": 21000
    },
    {
      "epoch": 0.842,
      "grad_norm": 0.28617623448371887,
      "learning_rate": 3.1608000000000007e-06,
      "loss": 0.0971749210357666,
      "step": 21050
    },
    {
      "epoch": 0.844,
      "grad_norm": 0.1174682006239891,
      "learning_rate": 3.1208000000000007e-06,
      "loss": 0.12794649124145507,
      "step": 21100
    },
    {
      "epoch": 0.846,
      "grad_norm": 0.007599300239235163,
      "learning_rate": 3.0808000000000006e-06,
      "loss": 0.14282833099365233,
      "step": 21150
    },
    {
      "epoch": 0.848,
      "grad_norm": 0.029142824932932854,
      "learning_rate": 3.0408000000000006e-06,
      "loss": 0.13694118499755858,
      "step": 21200
    },
    {
      "epoch": 0.85,
      "grad_norm": 18.170021057128906,
      "learning_rate": 3.0008000000000006e-06,
      "loss": 0.16603679656982423,
      "step": 21250
    },
    {
      "epoch": 0.852,
      "grad_norm": 12.468461036682129,
      "learning_rate": 2.9608000000000005e-06,
      "loss": 0.17445497512817382,
      "step": 21300
    },
    {
      "epoch": 0.854,
      "grad_norm": 0.2870655655860901,
      "learning_rate": 2.9208000000000005e-06,
      "loss": 0.13098066329956054,
      "step": 21350
    },
    {
      "epoch": 0.856,
      "grad_norm": 0.7036479115486145,
      "learning_rate": 2.8808000000000004e-06,
      "loss": 0.13200703620910645,
      "step": 21400
    },
    {
      "epoch": 0.858,
      "grad_norm": 7.656728744506836,
      "learning_rate": 2.8408000000000004e-06,
      "loss": 0.12702398300170897,
      "step": 21450
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.79234379529953,
      "learning_rate": 2.8008000000000004e-06,
      "loss": 0.10856478691101074,
      "step": 21500
    },
    {
      "epoch": 0.862,
      "grad_norm": 1.6706106662750244,
      "learning_rate": 2.7608000000000003e-06,
      "loss": 0.11919679641723632,
      "step": 21550
    },
    {
      "epoch": 0.864,
      "grad_norm": 0.062193792313337326,
      "learning_rate": 2.7208000000000003e-06,
      "loss": 0.0868376350402832,
      "step": 21600
    },
    {
      "epoch": 0.866,
      "grad_norm": 0.029926054179668427,
      "learning_rate": 2.6808000000000002e-06,
      "loss": 0.0509609842300415,
      "step": 21650
    },
    {
      "epoch": 0.868,
      "grad_norm": 0.2252957671880722,
      "learning_rate": 2.6408e-06,
      "loss": 0.18760984420776367,
      "step": 21700
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.10490674525499344,
      "learning_rate": 2.6008e-06,
      "loss": 0.18429874420166015,
      "step": 21750
    },
    {
      "epoch": 0.872,
      "grad_norm": 0.10233407467603683,
      "learning_rate": 2.5608e-06,
      "loss": 0.10888970375061036,
      "step": 21800
    },
    {
      "epoch": 0.874,
      "grad_norm": 0.03115048259496689,
      "learning_rate": 2.5208000000000005e-06,
      "loss": 0.0912589168548584,
      "step": 21850
    },
    {
      "epoch": 0.876,
      "grad_norm": 29.206390380859375,
      "learning_rate": 2.4808e-06,
      "loss": 0.15161870002746583,
      "step": 21900
    },
    {
      "epoch": 0.878,
      "grad_norm": 24.911922454833984,
      "learning_rate": 2.4408e-06,
      "loss": 0.2973150634765625,
      "step": 21950
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.14870549738407135,
      "learning_rate": 2.4008e-06,
      "loss": 0.1298624610900879,
      "step": 22000
    },
    {
      "epoch": 0.882,
      "grad_norm": 17.1334171295166,
      "learning_rate": 2.3608000000000003e-06,
      "loss": 0.1605390739440918,
      "step": 22050
    },
    {
      "epoch": 0.884,
      "grad_norm": 2.7658181190490723,
      "learning_rate": 2.3208000000000003e-06,
      "loss": 0.15816285133361815,
      "step": 22100
    },
    {
      "epoch": 0.886,
      "grad_norm": 0.016318021342158318,
      "learning_rate": 2.2808000000000003e-06,
      "loss": 0.12705065727233886,
      "step": 22150
    },
    {
      "epoch": 0.888,
      "grad_norm": 0.029429588466882706,
      "learning_rate": 2.2408000000000002e-06,
      "loss": 0.11445925712585449,
      "step": 22200
    },
    {
      "epoch": 0.89,
      "grad_norm": 6.132472991943359,
      "learning_rate": 2.2008e-06,
      "loss": 0.13712838172912598,
      "step": 22250
    },
    {
      "epoch": 0.892,
      "grad_norm": 9.274250030517578,
      "learning_rate": 2.1608e-06,
      "loss": 0.12817001342773438,
      "step": 22300
    },
    {
      "epoch": 0.894,
      "grad_norm": 13.878340721130371,
      "learning_rate": 2.1208e-06,
      "loss": 0.08386388778686524,
      "step": 22350
    },
    {
      "epoch": 0.896,
      "grad_norm": 0.06829263269901276,
      "learning_rate": 2.0808e-06,
      "loss": 0.15941144943237304,
      "step": 22400
    },
    {
      "epoch": 0.898,
      "grad_norm": 0.27917250990867615,
      "learning_rate": 2.0408000000000004e-06,
      "loss": 0.11912896156311036,
      "step": 22450
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.2389814406633377,
      "learning_rate": 2.0008000000000004e-06,
      "loss": 0.08053778648376465,
      "step": 22500
    },
    {
      "epoch": 0.902,
      "grad_norm": 1.1136765480041504,
      "learning_rate": 1.9608000000000004e-06,
      "loss": 0.19835321426391603,
      "step": 22550
    },
    {
      "epoch": 0.904,
      "grad_norm": 0.02711142785847187,
      "learning_rate": 1.9208000000000003e-06,
      "loss": 0.17216516494750977,
      "step": 22600
    },
    {
      "epoch": 0.906,
      "grad_norm": 8.831412315368652,
      "learning_rate": 1.8808e-06,
      "loss": 0.20388439178466797,
      "step": 22650
    },
    {
      "epoch": 0.908,
      "grad_norm": 0.1471044272184372,
      "learning_rate": 1.8408e-06,
      "loss": 0.11671676635742187,
      "step": 22700
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.049358606338501,
      "learning_rate": 1.8008e-06,
      "loss": 0.11402429580688477,
      "step": 22750
    },
    {
      "epoch": 0.912,
      "grad_norm": 0.15833185613155365,
      "learning_rate": 1.7608e-06,
      "loss": 0.10991607666015625,
      "step": 22800
    },
    {
      "epoch": 0.914,
      "grad_norm": 9.075617790222168,
      "learning_rate": 1.7208000000000003e-06,
      "loss": 0.22055118560791015,
      "step": 22850
    },
    {
      "epoch": 0.916,
      "grad_norm": 0.025399217382073402,
      "learning_rate": 1.6808000000000003e-06,
      "loss": 0.12068958282470703,
      "step": 22900
    },
    {
      "epoch": 0.918,
      "grad_norm": 0.033008553087711334,
      "learning_rate": 1.6408000000000002e-06,
      "loss": 0.1296784210205078,
      "step": 22950
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.9193663597106934,
      "learning_rate": 1.6008000000000002e-06,
      "loss": 0.17306636810302733,
      "step": 23000
    },
    {
      "epoch": 0.922,
      "grad_norm": 0.19889795780181885,
      "learning_rate": 1.5608000000000002e-06,
      "loss": 0.08715819358825684,
      "step": 23050
    },
    {
      "epoch": 0.924,
      "grad_norm": 0.08802248537540436,
      "learning_rate": 1.5208000000000001e-06,
      "loss": 0.1627946090698242,
      "step": 23100
    },
    {
      "epoch": 0.926,
      "grad_norm": 7.305597305297852,
      "learning_rate": 1.4808e-06,
      "loss": 0.13191838264465333,
      "step": 23150
    },
    {
      "epoch": 0.928,
      "grad_norm": 9.199923515319824,
      "learning_rate": 1.4408000000000002e-06,
      "loss": 0.1305930233001709,
      "step": 23200
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.10602567344903946,
      "learning_rate": 1.4008000000000002e-06,
      "loss": 0.09581109046936036,
      "step": 23250
    },
    {
      "epoch": 0.932,
      "grad_norm": 0.27565881609916687,
      "learning_rate": 1.3608000000000002e-06,
      "loss": 0.17571735382080078,
      "step": 23300
    },
    {
      "epoch": 0.934,
      "grad_norm": 10.100770950317383,
      "learning_rate": 1.3208000000000001e-06,
      "loss": 0.17300756454467772,
      "step": 23350
    },
    {
      "epoch": 0.936,
      "grad_norm": 0.05188290402293205,
      "learning_rate": 1.2808e-06,
      "loss": 0.13693912506103514,
      "step": 23400
    },
    {
      "epoch": 0.938,
      "grad_norm": 0.35082581639289856,
      "learning_rate": 1.2408e-06,
      "loss": 0.0859223747253418,
      "step": 23450
    },
    {
      "epoch": 0.94,
      "grad_norm": 3.9884893894195557,
      "learning_rate": 1.2008000000000002e-06,
      "loss": 0.15008278846740722,
      "step": 23500
    },
    {
      "epoch": 0.942,
      "grad_norm": 8.86812686920166,
      "learning_rate": 1.1608000000000002e-06,
      "loss": 0.1395544719696045,
      "step": 23550
    },
    {
      "epoch": 0.944,
      "grad_norm": 6.783252716064453,
      "learning_rate": 1.1208000000000001e-06,
      "loss": 0.1279418182373047,
      "step": 23600
    },
    {
      "epoch": 0.946,
      "grad_norm": 0.13628903031349182,
      "learning_rate": 1.0808e-06,
      "loss": 0.14378235816955567,
      "step": 23650
    },
    {
      "epoch": 0.948,
      "grad_norm": 0.1241859719157219,
      "learning_rate": 1.0408e-06,
      "loss": 0.16237081527709962,
      "step": 23700
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.04902215674519539,
      "learning_rate": 1.0008e-06,
      "loss": 0.08144959449768066,
      "step": 23750
    },
    {
      "epoch": 0.952,
      "grad_norm": 0.09727384895086288,
      "learning_rate": 9.608e-07,
      "loss": 0.11589853286743164,
      "step": 23800
    },
    {
      "epoch": 0.954,
      "grad_norm": 0.418362557888031,
      "learning_rate": 9.208e-07,
      "loss": 0.11425571441650391,
      "step": 23850
    },
    {
      "epoch": 0.956,
      "grad_norm": 0.2348676323890686,
      "learning_rate": 8.808000000000001e-07,
      "loss": 0.1480625629425049,
      "step": 23900
    },
    {
      "epoch": 0.958,
      "grad_norm": 0.1785469353199005,
      "learning_rate": 8.408000000000001e-07,
      "loss": 0.06054502487182617,
      "step": 23950
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.10582644492387772,
      "learning_rate": 8.008e-07,
      "loss": 0.14341023445129394,
      "step": 24000
    },
    {
      "epoch": 0.962,
      "grad_norm": 0.02670343406498432,
      "learning_rate": 7.608e-07,
      "loss": 0.12226910591125488,
      "step": 24050
    },
    {
      "epoch": 0.964,
      "grad_norm": 0.21534191071987152,
      "learning_rate": 7.208000000000002e-07,
      "loss": 0.14248918533325194,
      "step": 24100
    },
    {
      "epoch": 0.966,
      "grad_norm": 0.03390868753194809,
      "learning_rate": 6.808000000000001e-07,
      "loss": 0.08550265312194824,
      "step": 24150
    },
    {
      "epoch": 0.968,
      "grad_norm": 0.8533817529678345,
      "learning_rate": 6.408000000000001e-07,
      "loss": 0.17255393981933595,
      "step": 24200
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.5962009429931641,
      "learning_rate": 6.008e-07,
      "loss": 0.1563446617126465,
      "step": 24250
    },
    {
      "epoch": 0.972,
      "grad_norm": 0.02522612176835537,
      "learning_rate": 5.608e-07,
      "loss": 0.12441417694091797,
      "step": 24300
    },
    {
      "epoch": 0.974,
      "grad_norm": 0.17641115188598633,
      "learning_rate": 5.208000000000001e-07,
      "loss": 0.19129688262939454,
      "step": 24350
    },
    {
      "epoch": 0.976,
      "grad_norm": 1.5587977170944214,
      "learning_rate": 4.808e-07,
      "loss": 0.1492634105682373,
      "step": 24400
    },
    {
      "epoch": 0.978,
      "grad_norm": 0.13339141011238098,
      "learning_rate": 4.4080000000000003e-07,
      "loss": 0.08636626243591308,
      "step": 24450
    },
    {
      "epoch": 0.98,
      "grad_norm": 6.981259346008301,
      "learning_rate": 4.008e-07,
      "loss": 0.13709016799926757,
      "step": 24500
    }
  ],
  "logging_steps": 50,
  "max_steps": 25000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 4868263717632000.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
