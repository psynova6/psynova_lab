{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 25000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.002,
      "grad_norm": 2.773420572280884,
      "learning_rate": 1.9960800000000004e-05,
      "loss": 0.6648860931396484,
      "step": 50
    },
    {
      "epoch": 0.004,
      "grad_norm": 0.9320639967918396,
      "learning_rate": 1.99208e-05,
      "loss": 0.35781551361083985,
      "step": 100
    },
    {
      "epoch": 0.006,
      "grad_norm": 3.907571315765381,
      "learning_rate": 1.98808e-05,
      "loss": 0.3782196044921875,
      "step": 150
    },
    {
      "epoch": 0.008,
      "grad_norm": 37.26713943481445,
      "learning_rate": 1.98408e-05,
      "loss": 0.5097383880615234,
      "step": 200
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.1971762776374817,
      "learning_rate": 1.9800800000000002e-05,
      "loss": 0.40051883697509766,
      "step": 250
    },
    {
      "epoch": 0.012,
      "grad_norm": 9.164772033691406,
      "learning_rate": 1.9760800000000002e-05,
      "loss": 0.3248746871948242,
      "step": 300
    },
    {
      "epoch": 0.014,
      "grad_norm": 0.21226267516613007,
      "learning_rate": 1.9720800000000003e-05,
      "loss": 0.43684993743896483,
      "step": 350
    },
    {
      "epoch": 0.016,
      "grad_norm": 0.4724005162715912,
      "learning_rate": 1.9680800000000003e-05,
      "loss": 0.46420970916748044,
      "step": 400
    },
    {
      "epoch": 0.018,
      "grad_norm": 0.23584219813346863,
      "learning_rate": 1.9640800000000003e-05,
      "loss": 0.23014204025268556,
      "step": 450
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.05700220167636871,
      "learning_rate": 1.96008e-05,
      "loss": 0.3387200927734375,
      "step": 500
    },
    {
      "epoch": 0.022,
      "grad_norm": 0.26346585154533386,
      "learning_rate": 1.95608e-05,
      "loss": 0.3345696258544922,
      "step": 550
    },
    {
      "epoch": 0.024,
      "grad_norm": 174.2685546875,
      "learning_rate": 1.95208e-05,
      "loss": 0.19927135467529297,
      "step": 600
    },
    {
      "epoch": 0.026,
      "grad_norm": 0.07117561250925064,
      "learning_rate": 1.94808e-05,
      "loss": 0.27622634887695313,
      "step": 650
    },
    {
      "epoch": 0.028,
      "grad_norm": 0.05707533657550812,
      "learning_rate": 1.9440800000000002e-05,
      "loss": 0.19694561004638672,
      "step": 700
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.032936710864305496,
      "learning_rate": 1.9400800000000002e-05,
      "loss": 0.3707843780517578,
      "step": 750
    },
    {
      "epoch": 0.032,
      "grad_norm": 21.887454986572266,
      "learning_rate": 1.9360800000000003e-05,
      "loss": 0.33714302062988283,
      "step": 800
    },
    {
      "epoch": 0.034,
      "grad_norm": 0.07933047413825989,
      "learning_rate": 1.9320800000000003e-05,
      "loss": 0.4302793884277344,
      "step": 850
    },
    {
      "epoch": 0.036,
      "grad_norm": 31.7764835357666,
      "learning_rate": 1.92808e-05,
      "loss": 0.3723727035522461,
      "step": 900
    },
    {
      "epoch": 0.038,
      "grad_norm": 15.27505874633789,
      "learning_rate": 1.92408e-05,
      "loss": 0.31785102844238283,
      "step": 950
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.42003604769706726,
      "learning_rate": 1.92008e-05,
      "loss": 0.3694390869140625,
      "step": 1000
    },
    {
      "epoch": 0.042,
      "grad_norm": 0.3419986665248871,
      "learning_rate": 1.91608e-05,
      "loss": 0.42788097381591794,
      "step": 1050
    },
    {
      "epoch": 0.044,
      "grad_norm": 9.928519248962402,
      "learning_rate": 1.91208e-05,
      "loss": 0.27841108322143554,
      "step": 1100
    },
    {
      "epoch": 0.046,
      "grad_norm": 0.08173700422048569,
      "learning_rate": 1.9080800000000002e-05,
      "loss": 0.31304790496826174,
      "step": 1150
    },
    {
      "epoch": 0.048,
      "grad_norm": 0.2271914780139923,
      "learning_rate": 1.9040800000000002e-05,
      "loss": 0.2576640510559082,
      "step": 1200
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.0687079057097435,
      "learning_rate": 1.9000800000000003e-05,
      "loss": 0.3133265495300293,
      "step": 1250
    },
    {
      "epoch": 0.052,
      "grad_norm": 0.030600614845752716,
      "learning_rate": 1.89608e-05,
      "loss": 0.22149763107299805,
      "step": 1300
    },
    {
      "epoch": 0.054,
      "grad_norm": 0.051068857312202454,
      "learning_rate": 1.89208e-05,
      "loss": 0.19665212631225587,
      "step": 1350
    },
    {
      "epoch": 0.056,
      "grad_norm": 0.06828562170267105,
      "learning_rate": 1.88808e-05,
      "loss": 0.36569034576416015,
      "step": 1400
    },
    {
      "epoch": 0.058,
      "grad_norm": 101.5624771118164,
      "learning_rate": 1.88408e-05,
      "loss": 0.14826062202453613,
      "step": 1450
    },
    {
      "epoch": 0.06,
      "grad_norm": 102.3053970336914,
      "learning_rate": 1.88008e-05,
      "loss": 0.3940376663208008,
      "step": 1500
    },
    {
      "epoch": 0.062,
      "grad_norm": 0.1366870403289795,
      "learning_rate": 1.8760800000000002e-05,
      "loss": 0.34810298919677735,
      "step": 1550
    },
    {
      "epoch": 0.064,
      "grad_norm": 0.12189194560050964,
      "learning_rate": 1.8720800000000002e-05,
      "loss": 0.22317567825317383,
      "step": 1600
    },
    {
      "epoch": 0.066,
      "grad_norm": 0.2192409783601761,
      "learning_rate": 1.8680800000000002e-05,
      "loss": 0.2884358787536621,
      "step": 1650
    },
    {
      "epoch": 0.068,
      "grad_norm": 0.027509476989507675,
      "learning_rate": 1.86408e-05,
      "loss": 0.19887741088867186,
      "step": 1700
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.013870369642972946,
      "learning_rate": 1.86008e-05,
      "loss": 0.2359199905395508,
      "step": 1750
    },
    {
      "epoch": 0.072,
      "grad_norm": 0.12393297255039215,
      "learning_rate": 1.85608e-05,
      "loss": 0.25929042816162107,
      "step": 1800
    },
    {
      "epoch": 0.074,
      "grad_norm": 35.263633728027344,
      "learning_rate": 1.85208e-05,
      "loss": 0.30471946716308596,
      "step": 1850
    },
    {
      "epoch": 0.076,
      "grad_norm": 0.0630212053656578,
      "learning_rate": 1.84808e-05,
      "loss": 0.4069180679321289,
      "step": 1900
    },
    {
      "epoch": 0.078,
      "grad_norm": 0.11614838987588882,
      "learning_rate": 1.84408e-05,
      "loss": 0.13363905906677245,
      "step": 1950
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.02717277966439724,
      "learning_rate": 1.8400800000000002e-05,
      "loss": 0.2895399856567383,
      "step": 2000
    },
    {
      "epoch": 0.082,
      "grad_norm": 1.236000895500183,
      "learning_rate": 1.8360800000000002e-05,
      "loss": 0.2345356559753418,
      "step": 2050
    },
    {
      "epoch": 0.084,
      "grad_norm": 0.0762551873922348,
      "learning_rate": 1.83208e-05,
      "loss": 0.21047622680664063,
      "step": 2100
    },
    {
      "epoch": 0.086,
      "grad_norm": 66.52156066894531,
      "learning_rate": 1.82808e-05,
      "loss": 0.2377943801879883,
      "step": 2150
    },
    {
      "epoch": 0.088,
      "grad_norm": 0.03776080906391144,
      "learning_rate": 1.82408e-05,
      "loss": 0.25033843994140625,
      "step": 2200
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.1414812058210373,
      "learning_rate": 1.82008e-05,
      "loss": 0.3168322563171387,
      "step": 2250
    },
    {
      "epoch": 0.092,
      "grad_norm": 0.02339915931224823,
      "learning_rate": 1.81608e-05,
      "loss": 0.21866519927978514,
      "step": 2300
    },
    {
      "epoch": 0.094,
      "grad_norm": 0.31836938858032227,
      "learning_rate": 1.81208e-05,
      "loss": 0.2929603958129883,
      "step": 2350
    },
    {
      "epoch": 0.096,
      "grad_norm": 0.0791492760181427,
      "learning_rate": 1.80808e-05,
      "loss": 0.34151042938232423,
      "step": 2400
    },
    {
      "epoch": 0.098,
      "grad_norm": 0.23711331188678741,
      "learning_rate": 1.8040800000000002e-05,
      "loss": 0.12792510986328126,
      "step": 2450
    },
    {
      "epoch": 0.1,
      "grad_norm": 4.386937141418457,
      "learning_rate": 1.80008e-05,
      "loss": 0.3307870101928711,
      "step": 2500
    },
    {
      "epoch": 0.102,
      "grad_norm": 0.05189719796180725,
      "learning_rate": 1.79608e-05,
      "loss": 0.17244131088256837,
      "step": 2550
    },
    {
      "epoch": 0.104,
      "grad_norm": 0.032919351011514664,
      "learning_rate": 1.79208e-05,
      "loss": 0.2095327568054199,
      "step": 2600
    },
    {
      "epoch": 0.106,
      "grad_norm": 0.15005335211753845,
      "learning_rate": 1.78808e-05,
      "loss": 0.34300811767578127,
      "step": 2650
    },
    {
      "epoch": 0.108,
      "grad_norm": 0.047965455800294876,
      "learning_rate": 1.7840800000000004e-05,
      "loss": 0.27239091873168947,
      "step": 2700
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.050755277276039124,
      "learning_rate": 1.7800800000000004e-05,
      "loss": 0.16486328125,
      "step": 2750
    },
    {
      "epoch": 0.112,
      "grad_norm": 0.6974803805351257,
      "learning_rate": 1.77608e-05,
      "loss": 0.27106107711791994,
      "step": 2800
    },
    {
      "epoch": 0.114,
      "grad_norm": 11.060056686401367,
      "learning_rate": 1.77208e-05,
      "loss": 0.2973044395446777,
      "step": 2850
    },
    {
      "epoch": 0.116,
      "grad_norm": 0.09633279591798782,
      "learning_rate": 1.7680800000000002e-05,
      "loss": 0.3053951454162598,
      "step": 2900
    },
    {
      "epoch": 0.118,
      "grad_norm": 0.2380884885787964,
      "learning_rate": 1.7640800000000002e-05,
      "loss": 0.3509761047363281,
      "step": 2950
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.12977831065654755,
      "learning_rate": 1.7600800000000003e-05,
      "loss": 0.2246255874633789,
      "step": 3000
    },
    {
      "epoch": 0.122,
      "grad_norm": 1.0936914682388306,
      "learning_rate": 1.7560800000000003e-05,
      "loss": 0.15870925903320313,
      "step": 3050
    },
    {
      "epoch": 0.124,
      "grad_norm": 0.017546672374010086,
      "learning_rate": 1.7520800000000003e-05,
      "loss": 0.2010670471191406,
      "step": 3100
    },
    {
      "epoch": 0.126,
      "grad_norm": 18.045122146606445,
      "learning_rate": 1.7480800000000004e-05,
      "loss": 0.21544235229492187,
      "step": 3150
    },
    {
      "epoch": 0.128,
      "grad_norm": 84.74647521972656,
      "learning_rate": 1.74408e-05,
      "loss": 0.2424184799194336,
      "step": 3200
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.7353564500808716,
      "learning_rate": 1.74008e-05,
      "loss": 0.2308945846557617,
      "step": 3250
    },
    {
      "epoch": 0.132,
      "grad_norm": 11.339011192321777,
      "learning_rate": 1.73608e-05,
      "loss": 0.25265830993652344,
      "step": 3300
    },
    {
      "epoch": 0.134,
      "grad_norm": 0.020381765440106392,
      "learning_rate": 1.7320800000000002e-05,
      "loss": 0.11719324111938477,
      "step": 3350
    },
    {
      "epoch": 0.136,
      "grad_norm": 0.022948525846004486,
      "learning_rate": 1.7280800000000002e-05,
      "loss": 0.17588167190551757,
      "step": 3400
    },
    {
      "epoch": 0.138,
      "grad_norm": 0.08117002248764038,
      "learning_rate": 1.7240800000000003e-05,
      "loss": 0.39865604400634763,
      "step": 3450
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.0870371162891388,
      "learning_rate": 1.7200800000000003e-05,
      "loss": 0.19436206817626953,
      "step": 3500
    },
    {
      "epoch": 0.142,
      "grad_norm": 0.06703518331050873,
      "learning_rate": 1.7160800000000003e-05,
      "loss": 0.12927623748779296,
      "step": 3550
    },
    {
      "epoch": 0.144,
      "grad_norm": 0.26847875118255615,
      "learning_rate": 1.71208e-05,
      "loss": 0.2934817886352539,
      "step": 3600
    },
    {
      "epoch": 0.146,
      "grad_norm": 37.31741714477539,
      "learning_rate": 1.70808e-05,
      "loss": 0.22611547470092774,
      "step": 3650
    },
    {
      "epoch": 0.148,
      "grad_norm": 0.8461456894874573,
      "learning_rate": 1.70408e-05,
      "loss": 0.16955101013183593,
      "step": 3700
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.02004903554916382,
      "learning_rate": 1.70008e-05,
      "loss": 0.11347028732299805,
      "step": 3750
    },
    {
      "epoch": 0.152,
      "grad_norm": 0.029248645529150963,
      "learning_rate": 1.6960800000000002e-05,
      "loss": 0.17029870986938478,
      "step": 3800
    },
    {
      "epoch": 0.154,
      "grad_norm": 0.009650083258748055,
      "learning_rate": 1.6920800000000002e-05,
      "loss": 0.27266273498535154,
      "step": 3850
    },
    {
      "epoch": 0.156,
      "grad_norm": 0.09188802540302277,
      "learning_rate": 1.6880800000000003e-05,
      "loss": 0.1998312568664551,
      "step": 3900
    },
    {
      "epoch": 0.158,
      "grad_norm": 0.35414111614227295,
      "learning_rate": 1.6840800000000003e-05,
      "loss": 0.33712440490722656,
      "step": 3950
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.08320078253746033,
      "learning_rate": 1.68008e-05,
      "loss": 0.3026458740234375,
      "step": 4000
    },
    {
      "epoch": 0.162,
      "grad_norm": 0.033885519951581955,
      "learning_rate": 1.67608e-05,
      "loss": 0.15347959518432616,
      "step": 4050
    },
    {
      "epoch": 0.164,
      "grad_norm": 0.029494984075427055,
      "learning_rate": 1.67208e-05,
      "loss": 0.16944040298461915,
      "step": 4100
    },
    {
      "epoch": 0.166,
      "grad_norm": 0.1150951236486435,
      "learning_rate": 1.66808e-05,
      "loss": 0.18127361297607422,
      "step": 4150
    },
    {
      "epoch": 0.168,
      "grad_norm": 42.55602264404297,
      "learning_rate": 1.66408e-05,
      "loss": 0.15917861938476563,
      "step": 4200
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.035162802785634995,
      "learning_rate": 1.6600800000000002e-05,
      "loss": 0.20267187118530272,
      "step": 4250
    },
    {
      "epoch": 0.172,
      "grad_norm": 0.02442556619644165,
      "learning_rate": 1.6560800000000002e-05,
      "loss": 0.15647016525268553,
      "step": 4300
    },
    {
      "epoch": 0.174,
      "grad_norm": 0.1599668562412262,
      "learning_rate": 1.6520800000000003e-05,
      "loss": 0.32270912170410154,
      "step": 4350
    },
    {
      "epoch": 0.176,
      "grad_norm": 0.0314808115363121,
      "learning_rate": 1.64808e-05,
      "loss": 0.1897148895263672,
      "step": 4400
    },
    {
      "epoch": 0.178,
      "grad_norm": 36.83898162841797,
      "learning_rate": 1.64408e-05,
      "loss": 0.2163739013671875,
      "step": 4450
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.04271046444773674,
      "learning_rate": 1.64008e-05,
      "loss": 0.29929174423217775,
      "step": 4500
    },
    {
      "epoch": 0.182,
      "grad_norm": 126.5323257446289,
      "learning_rate": 1.63608e-05,
      "loss": 0.31755670547485354,
      "step": 4550
    },
    {
      "epoch": 0.184,
      "grad_norm": 58.089820861816406,
      "learning_rate": 1.63208e-05,
      "loss": 0.20180837631225587,
      "step": 4600
    },
    {
      "epoch": 0.186,
      "grad_norm": 0.045014217495918274,
      "learning_rate": 1.6280800000000002e-05,
      "loss": 0.1539646339416504,
      "step": 4650
    },
    {
      "epoch": 0.188,
      "grad_norm": 0.015806423500180244,
      "learning_rate": 1.6240800000000002e-05,
      "loss": 0.18973539352416993,
      "step": 4700
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.015243884176015854,
      "learning_rate": 1.6200800000000003e-05,
      "loss": 0.31354801177978514,
      "step": 4750
    },
    {
      "epoch": 0.192,
      "grad_norm": 124.81375885009766,
      "learning_rate": 1.61608e-05,
      "loss": 0.26467864990234374,
      "step": 4800
    },
    {
      "epoch": 0.194,
      "grad_norm": 0.09446069598197937,
      "learning_rate": 1.61208e-05,
      "loss": 0.2893680572509766,
      "step": 4850
    },
    {
      "epoch": 0.196,
      "grad_norm": 0.07547751069068909,
      "learning_rate": 1.60808e-05,
      "loss": 0.24859663009643554,
      "step": 4900
    },
    {
      "epoch": 0.198,
      "grad_norm": 0.022588595747947693,
      "learning_rate": 1.60408e-05,
      "loss": 0.16754961013793945,
      "step": 4950
    },
    {
      "epoch": 0.2,
      "grad_norm": 24.466455459594727,
      "learning_rate": 1.60008e-05,
      "loss": 0.2638862991333008,
      "step": 5000
    },
    {
      "epoch": 0.202,
      "grad_norm": 2.112077236175537,
      "learning_rate": 1.59608e-05,
      "loss": 0.18095985412597657,
      "step": 5050
    },
    {
      "epoch": 0.204,
      "grad_norm": 0.026282787322998047,
      "learning_rate": 1.5920800000000002e-05,
      "loss": 0.20280773162841798,
      "step": 5100
    },
    {
      "epoch": 0.206,
      "grad_norm": 30.877309799194336,
      "learning_rate": 1.5880800000000002e-05,
      "loss": 0.26136768341064454,
      "step": 5150
    },
    {
      "epoch": 0.208,
      "grad_norm": 0.0681702047586441,
      "learning_rate": 1.58408e-05,
      "loss": 0.2665505599975586,
      "step": 5200
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.07349017262458801,
      "learning_rate": 1.58008e-05,
      "loss": 0.11538262367248535,
      "step": 5250
    },
    {
      "epoch": 0.212,
      "grad_norm": 0.027332156896591187,
      "learning_rate": 1.57608e-05,
      "loss": 0.25921270370483396,
      "step": 5300
    },
    {
      "epoch": 0.214,
      "grad_norm": 62.54331588745117,
      "learning_rate": 1.57208e-05,
      "loss": 0.2366301918029785,
      "step": 5350
    },
    {
      "epoch": 0.216,
      "grad_norm": 0.23238053917884827,
      "learning_rate": 1.56808e-05,
      "loss": 0.2618428802490234,
      "step": 5400
    },
    {
      "epoch": 0.218,
      "grad_norm": 0.11763674020767212,
      "learning_rate": 1.56408e-05,
      "loss": 0.22902803421020507,
      "step": 5450
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.13372832536697388,
      "learning_rate": 1.56008e-05,
      "loss": 0.3353267288208008,
      "step": 5500
    },
    {
      "epoch": 0.222,
      "grad_norm": 0.06199607625603676,
      "learning_rate": 1.5560800000000002e-05,
      "loss": 0.1492752456665039,
      "step": 5550
    },
    {
      "epoch": 0.224,
      "grad_norm": 0.11351577937602997,
      "learning_rate": 1.55208e-05,
      "loss": 0.45478477478027346,
      "step": 5600
    },
    {
      "epoch": 0.226,
      "grad_norm": 0.4657159149646759,
      "learning_rate": 1.54808e-05,
      "loss": 0.3071809959411621,
      "step": 5650
    },
    {
      "epoch": 0.228,
      "grad_norm": 0.12458731979131699,
      "learning_rate": 1.54408e-05,
      "loss": 0.20259794235229492,
      "step": 5700
    },
    {
      "epoch": 0.23,
      "grad_norm": 26.09075164794922,
      "learning_rate": 1.54008e-05,
      "loss": 0.23532556533813476,
      "step": 5750
    },
    {
      "epoch": 0.232,
      "grad_norm": 0.09943727403879166,
      "learning_rate": 1.53608e-05,
      "loss": 0.32948638916015627,
      "step": 5800
    },
    {
      "epoch": 0.234,
      "grad_norm": 0.40800005197525024,
      "learning_rate": 1.53208e-05,
      "loss": 0.1493896198272705,
      "step": 5850
    },
    {
      "epoch": 0.236,
      "grad_norm": 0.2559642195701599,
      "learning_rate": 1.52808e-05,
      "loss": 0.30592214584350585,
      "step": 5900
    },
    {
      "epoch": 0.238,
      "grad_norm": 0.10889500379562378,
      "learning_rate": 1.5240800000000002e-05,
      "loss": 0.14663358688354491,
      "step": 5950
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.01406917069107294,
      "learning_rate": 1.5200800000000002e-05,
      "loss": 0.15033682823181152,
      "step": 6000
    },
    {
      "epoch": 0.242,
      "grad_norm": 0.17840783298015594,
      "learning_rate": 1.5160800000000002e-05,
      "loss": 0.2733741569519043,
      "step": 6050
    },
    {
      "epoch": 0.244,
      "grad_norm": 0.10661100596189499,
      "learning_rate": 1.5120800000000003e-05,
      "loss": 0.38207881927490234,
      "step": 6100
    },
    {
      "epoch": 0.246,
      "grad_norm": 0.30758821964263916,
      "learning_rate": 1.5080800000000001e-05,
      "loss": 0.09278635025024413,
      "step": 6150
    },
    {
      "epoch": 0.248,
      "grad_norm": 0.09999925643205643,
      "learning_rate": 1.5040800000000002e-05,
      "loss": 0.1275387668609619,
      "step": 6200
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.05006340891122818,
      "learning_rate": 1.5000800000000002e-05,
      "loss": 0.273906307220459,
      "step": 6250
    },
    {
      "epoch": 0.252,
      "grad_norm": 11.42579174041748,
      "learning_rate": 1.4960800000000003e-05,
      "loss": 0.3317325210571289,
      "step": 6300
    },
    {
      "epoch": 0.254,
      "grad_norm": 0.22386640310287476,
      "learning_rate": 1.4920800000000001e-05,
      "loss": 0.36816650390625,
      "step": 6350
    },
    {
      "epoch": 0.256,
      "grad_norm": 0.030288418754935265,
      "learning_rate": 1.4880800000000002e-05,
      "loss": 0.1401207160949707,
      "step": 6400
    },
    {
      "epoch": 0.258,
      "grad_norm": 35.93868637084961,
      "learning_rate": 1.4840800000000002e-05,
      "loss": 0.19715213775634766,
      "step": 6450
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.040030673146247864,
      "learning_rate": 1.4800800000000002e-05,
      "loss": 0.22942258834838866,
      "step": 6500
    },
    {
      "epoch": 0.262,
      "grad_norm": 0.03908805549144745,
      "learning_rate": 1.4760800000000001e-05,
      "loss": 0.19005279541015624,
      "step": 6550
    },
    {
      "epoch": 0.264,
      "grad_norm": 0.10382842272520065,
      "learning_rate": 1.4720800000000001e-05,
      "loss": 0.19968414306640625,
      "step": 6600
    },
    {
      "epoch": 0.266,
      "grad_norm": 0.09027817100286484,
      "learning_rate": 1.4680800000000002e-05,
      "loss": 0.1848244285583496,
      "step": 6650
    },
    {
      "epoch": 0.268,
      "grad_norm": 0.042517632246017456,
      "learning_rate": 1.4640800000000002e-05,
      "loss": 0.3020978164672852,
      "step": 6700
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.08895006775856018,
      "learning_rate": 1.4600800000000001e-05,
      "loss": 0.2446638298034668,
      "step": 6750
    },
    {
      "epoch": 0.272,
      "grad_norm": 0.2102758288383484,
      "learning_rate": 1.4560800000000001e-05,
      "loss": 0.19359565734863282,
      "step": 6800
    },
    {
      "epoch": 0.274,
      "grad_norm": 0.06504640728235245,
      "learning_rate": 1.4520800000000002e-05,
      "loss": 0.29119338989257815,
      "step": 6850
    },
    {
      "epoch": 0.276,
      "grad_norm": 0.056635309010744095,
      "learning_rate": 1.4480800000000002e-05,
      "loss": 0.2330344009399414,
      "step": 6900
    },
    {
      "epoch": 0.278,
      "grad_norm": 0.3715486526489258,
      "learning_rate": 1.44408e-05,
      "loss": 0.1531309413909912,
      "step": 6950
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.16921690106391907,
      "learning_rate": 1.4400800000000001e-05,
      "loss": 0.3493043899536133,
      "step": 7000
    },
    {
      "epoch": 0.282,
      "grad_norm": 0.03721098229289055,
      "learning_rate": 1.4360800000000001e-05,
      "loss": 0.1729990005493164,
      "step": 7050
    },
    {
      "epoch": 0.284,
      "grad_norm": 10.836363792419434,
      "learning_rate": 1.4320800000000002e-05,
      "loss": 0.16424835205078125,
      "step": 7100
    },
    {
      "epoch": 0.286,
      "grad_norm": 201.30747985839844,
      "learning_rate": 1.42808e-05,
      "loss": 0.18392799377441407,
      "step": 7150
    },
    {
      "epoch": 0.288,
      "grad_norm": 0.9189556241035461,
      "learning_rate": 1.4240800000000001e-05,
      "loss": 0.1686983299255371,
      "step": 7200
    },
    {
      "epoch": 0.29,
      "grad_norm": 78.78953552246094,
      "learning_rate": 1.4200800000000001e-05,
      "loss": 0.25868438720703124,
      "step": 7250
    },
    {
      "epoch": 0.292,
      "grad_norm": 0.013958294875919819,
      "learning_rate": 1.4160800000000002e-05,
      "loss": 0.12966073036193848,
      "step": 7300
    },
    {
      "epoch": 0.294,
      "grad_norm": 0.08573067933320999,
      "learning_rate": 1.41208e-05,
      "loss": 0.2429773712158203,
      "step": 7350
    },
    {
      "epoch": 0.296,
      "grad_norm": 0.28076139092445374,
      "learning_rate": 1.40808e-05,
      "loss": 0.29120014190673826,
      "step": 7400
    },
    {
      "epoch": 0.298,
      "grad_norm": 0.11006266623735428,
      "learning_rate": 1.4040800000000001e-05,
      "loss": 0.1451238536834717,
      "step": 7450
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.027323005720973015,
      "learning_rate": 1.4000800000000002e-05,
      "loss": 0.30547441482543947,
      "step": 7500
    },
    {
      "epoch": 0.302,
      "grad_norm": 10.944496154785156,
      "learning_rate": 1.39608e-05,
      "loss": 0.2628934097290039,
      "step": 7550
    },
    {
      "epoch": 0.304,
      "grad_norm": 0.5884296894073486,
      "learning_rate": 1.39208e-05,
      "loss": 0.1399406051635742,
      "step": 7600
    },
    {
      "epoch": 0.306,
      "grad_norm": 0.2296554148197174,
      "learning_rate": 1.3880800000000001e-05,
      "loss": 0.255547981262207,
      "step": 7650
    },
    {
      "epoch": 0.308,
      "grad_norm": 0.4869637191295624,
      "learning_rate": 1.3840800000000001e-05,
      "loss": 0.18256906509399415,
      "step": 7700
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.07701680064201355,
      "learning_rate": 1.38008e-05,
      "loss": 0.18618553161621093,
      "step": 7750
    },
    {
      "epoch": 0.312,
      "grad_norm": 0.024026168510317802,
      "learning_rate": 1.37608e-05,
      "loss": 0.17844898223876954,
      "step": 7800
    },
    {
      "epoch": 0.314,
      "grad_norm": 0.10381454974412918,
      "learning_rate": 1.37208e-05,
      "loss": 0.3831657028198242,
      "step": 7850
    },
    {
      "epoch": 0.316,
      "grad_norm": 0.015394446440041065,
      "learning_rate": 1.3680800000000001e-05,
      "loss": 0.15775867462158202,
      "step": 7900
    },
    {
      "epoch": 0.318,
      "grad_norm": 0.2844966650009155,
      "learning_rate": 1.36408e-05,
      "loss": 0.15784883499145508,
      "step": 7950
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.0229658093303442,
      "learning_rate": 1.36008e-05,
      "loss": 0.1401239490509033,
      "step": 8000
    },
    {
      "epoch": 0.322,
      "grad_norm": 0.09012185782194138,
      "learning_rate": 1.35608e-05,
      "loss": 0.2764344787597656,
      "step": 8050
    },
    {
      "epoch": 0.324,
      "grad_norm": 63.18663787841797,
      "learning_rate": 1.3520800000000001e-05,
      "loss": 0.22340160369873047,
      "step": 8100
    },
    {
      "epoch": 0.326,
      "grad_norm": 63.60249328613281,
      "learning_rate": 1.34808e-05,
      "loss": 0.3426284408569336,
      "step": 8150
    },
    {
      "epoch": 0.328,
      "grad_norm": 12.907200813293457,
      "learning_rate": 1.34408e-05,
      "loss": 0.2898178482055664,
      "step": 8200
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.04788898304104805,
      "learning_rate": 1.34008e-05,
      "loss": 0.18471391677856444,
      "step": 8250
    },
    {
      "epoch": 0.332,
      "grad_norm": 0.02575650066137314,
      "learning_rate": 1.3360800000000001e-05,
      "loss": 0.27068153381347654,
      "step": 8300
    },
    {
      "epoch": 0.334,
      "grad_norm": 38.16271209716797,
      "learning_rate": 1.33208e-05,
      "loss": 0.06814316749572753,
      "step": 8350
    },
    {
      "epoch": 0.336,
      "grad_norm": 0.014482639729976654,
      "learning_rate": 1.32808e-05,
      "loss": 0.16389764785766603,
      "step": 8400
    },
    {
      "epoch": 0.338,
      "grad_norm": 0.02639797143638134,
      "learning_rate": 1.32408e-05,
      "loss": 0.18769603729248047,
      "step": 8450
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.01669261045753956,
      "learning_rate": 1.32008e-05,
      "loss": 0.19273757934570312,
      "step": 8500
    },
    {
      "epoch": 0.342,
      "grad_norm": 164.3262939453125,
      "learning_rate": 1.31608e-05,
      "loss": 0.18486425399780274,
      "step": 8550
    },
    {
      "epoch": 0.344,
      "grad_norm": 0.028854696080088615,
      "learning_rate": 1.31208e-05,
      "loss": 0.21268423080444335,
      "step": 8600
    },
    {
      "epoch": 0.346,
      "grad_norm": 29.530271530151367,
      "learning_rate": 1.30808e-05,
      "loss": 0.2357225799560547,
      "step": 8650
    },
    {
      "epoch": 0.348,
      "grad_norm": 0.4013423025608063,
      "learning_rate": 1.30408e-05,
      "loss": 0.2588679504394531,
      "step": 8700
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.012525876052677631,
      "learning_rate": 1.30008e-05,
      "loss": 0.2613345527648926,
      "step": 8750
    },
    {
      "epoch": 0.352,
      "grad_norm": 62.72834777832031,
      "learning_rate": 1.29608e-05,
      "loss": 0.20162586212158204,
      "step": 8800
    },
    {
      "epoch": 0.354,
      "grad_norm": 95.18083190917969,
      "learning_rate": 1.29208e-05,
      "loss": 0.20564184188842774,
      "step": 8850
    },
    {
      "epoch": 0.356,
      "grad_norm": 0.06567555665969849,
      "learning_rate": 1.28808e-05,
      "loss": 0.21887720108032227,
      "step": 8900
    },
    {
      "epoch": 0.358,
      "grad_norm": 0.01527366042137146,
      "learning_rate": 1.2840800000000002e-05,
      "loss": 0.33337905883789065,
      "step": 8950
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.3380638360977173,
      "learning_rate": 1.2800800000000003e-05,
      "loss": 0.19595794677734374,
      "step": 9000
    },
    {
      "epoch": 0.362,
      "grad_norm": 0.023418070748448372,
      "learning_rate": 1.2760800000000002e-05,
      "loss": 0.14767696380615233,
      "step": 9050
    },
    {
      "epoch": 0.364,
      "grad_norm": 141.58929443359375,
      "learning_rate": 1.2720800000000002e-05,
      "loss": 0.23803293228149414,
      "step": 9100
    },
    {
      "epoch": 0.366,
      "grad_norm": 22.579008102416992,
      "learning_rate": 1.2680800000000002e-05,
      "loss": 0.19114095687866212,
      "step": 9150
    },
    {
      "epoch": 0.368,
      "grad_norm": 41.01689910888672,
      "learning_rate": 1.2640800000000003e-05,
      "loss": 0.28720643997192385,
      "step": 9200
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.535576105117798,
      "learning_rate": 1.2600800000000001e-05,
      "loss": 0.13809009552001952,
      "step": 9250
    },
    {
      "epoch": 0.372,
      "grad_norm": 1.049880862236023,
      "learning_rate": 1.2560800000000002e-05,
      "loss": 0.28991525650024413,
      "step": 9300
    },
    {
      "epoch": 0.374,
      "grad_norm": 0.016274169087409973,
      "learning_rate": 1.2520800000000002e-05,
      "loss": 0.2008900260925293,
      "step": 9350
    },
    {
      "epoch": 0.376,
      "grad_norm": 0.2860815227031708,
      "learning_rate": 1.2480800000000003e-05,
      "loss": 0.15686993598937987,
      "step": 9400
    },
    {
      "epoch": 0.378,
      "grad_norm": 0.3032287657260895,
      "learning_rate": 1.2440800000000001e-05,
      "loss": 0.20584943771362305,
      "step": 9450
    },
    {
      "epoch": 0.38,
      "grad_norm": 137.07261657714844,
      "learning_rate": 1.2400800000000002e-05,
      "loss": 0.22612892150878905,
      "step": 9500
    },
    {
      "epoch": 0.382,
      "grad_norm": 0.008317322470247746,
      "learning_rate": 1.2360800000000002e-05,
      "loss": 0.12356198310852051,
      "step": 9550
    },
    {
      "epoch": 0.384,
      "grad_norm": 0.09686072915792465,
      "learning_rate": 1.2320800000000002e-05,
      "loss": 0.21494047164916993,
      "step": 9600
    },
    {
      "epoch": 0.386,
      "grad_norm": 0.005418249871581793,
      "learning_rate": 1.2280800000000001e-05,
      "loss": 0.24107940673828124,
      "step": 9650
    },
    {
      "epoch": 0.388,
      "grad_norm": 5.049115180969238,
      "learning_rate": 1.2240800000000001e-05,
      "loss": 0.27904548645019533,
      "step": 9700
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.015223088674247265,
      "learning_rate": 1.2200800000000002e-05,
      "loss": 0.14383573532104493,
      "step": 9750
    },
    {
      "epoch": 0.392,
      "grad_norm": 0.022888077422976494,
      "learning_rate": 1.2160800000000002e-05,
      "loss": 0.22909286499023437,
      "step": 9800
    },
    {
      "epoch": 0.394,
      "grad_norm": 0.03761235624551773,
      "learning_rate": 1.2120800000000001e-05,
      "loss": 0.3296832275390625,
      "step": 9850
    },
    {
      "epoch": 0.396,
      "grad_norm": 0.35370492935180664,
      "learning_rate": 1.2080800000000001e-05,
      "loss": 0.3136848831176758,
      "step": 9900
    },
    {
      "epoch": 0.398,
      "grad_norm": 37.33197021484375,
      "learning_rate": 1.2040800000000002e-05,
      "loss": 0.06881034851074219,
      "step": 9950
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.0055704559199512005,
      "learning_rate": 1.2000800000000002e-05,
      "loss": 0.10944543838500977,
      "step": 10000
    },
    {
      "epoch": 0.402,
      "grad_norm": 0.014558061957359314,
      "learning_rate": 1.19608e-05,
      "loss": 0.22958925247192383,
      "step": 10050
    },
    {
      "epoch": 0.404,
      "grad_norm": 22.801361083984375,
      "learning_rate": 1.1920800000000001e-05,
      "loss": 0.2763136100769043,
      "step": 10100
    },
    {
      "epoch": 0.406,
      "grad_norm": 206.64370727539062,
      "learning_rate": 1.1880800000000002e-05,
      "loss": 0.1463419246673584,
      "step": 10150
    },
    {
      "epoch": 0.408,
      "grad_norm": 0.20879867672920227,
      "learning_rate": 1.1840800000000002e-05,
      "loss": 0.20911468505859376,
      "step": 10200
    },
    {
      "epoch": 0.41,
      "grad_norm": 32.008399963378906,
      "learning_rate": 1.18008e-05,
      "loss": 0.2202076530456543,
      "step": 10250
    },
    {
      "epoch": 0.412,
      "grad_norm": 0.03804125264286995,
      "learning_rate": 1.1760800000000001e-05,
      "loss": 0.24926855087280272,
      "step": 10300
    },
    {
      "epoch": 0.414,
      "grad_norm": 0.009768877178430557,
      "learning_rate": 1.1720800000000001e-05,
      "loss": 0.17580341339111327,
      "step": 10350
    },
    {
      "epoch": 0.416,
      "grad_norm": 0.07486220449209213,
      "learning_rate": 1.1680800000000002e-05,
      "loss": 0.27991933822631837,
      "step": 10400
    },
    {
      "epoch": 0.418,
      "grad_norm": 0.007849611341953278,
      "learning_rate": 1.16408e-05,
      "loss": 0.16024005889892579,
      "step": 10450
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.009622946381568909,
      "learning_rate": 1.16008e-05,
      "loss": 0.2225202751159668,
      "step": 10500
    },
    {
      "epoch": 0.422,
      "grad_norm": 0.027846859768033028,
      "learning_rate": 1.1560800000000001e-05,
      "loss": 0.30622177124023436,
      "step": 10550
    },
    {
      "epoch": 0.424,
      "grad_norm": 0.14039136469364166,
      "learning_rate": 1.1520800000000002e-05,
      "loss": 0.16506416320800782,
      "step": 10600
    },
    {
      "epoch": 0.426,
      "grad_norm": 0.02760687656700611,
      "learning_rate": 1.14808e-05,
      "loss": 0.1325731945037842,
      "step": 10650
    },
    {
      "epoch": 0.428,
      "grad_norm": 0.016439156606793404,
      "learning_rate": 1.14408e-05,
      "loss": 0.12180265426635742,
      "step": 10700
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.0187017023563385,
      "learning_rate": 1.1400800000000001e-05,
      "loss": 0.0692179536819458,
      "step": 10750
    },
    {
      "epoch": 0.432,
      "grad_norm": 0.3869003355503082,
      "learning_rate": 1.1360800000000001e-05,
      "loss": 0.17686403274536133,
      "step": 10800
    },
    {
      "epoch": 0.434,
      "grad_norm": 0.18942216038703918,
      "learning_rate": 1.13208e-05,
      "loss": 0.20370960235595703,
      "step": 10850
    },
    {
      "epoch": 0.436,
      "grad_norm": 0.02607976458966732,
      "learning_rate": 1.12808e-05,
      "loss": 0.20332670211791992,
      "step": 10900
    },
    {
      "epoch": 0.438,
      "grad_norm": 0.23895715177059174,
      "learning_rate": 1.1240800000000001e-05,
      "loss": 0.25252126693725585,
      "step": 10950
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.06905119121074677,
      "learning_rate": 1.1200800000000001e-05,
      "loss": 0.30701656341552735,
      "step": 11000
    },
    {
      "epoch": 0.442,
      "grad_norm": 0.018371812999248505,
      "learning_rate": 1.11608e-05,
      "loss": 0.17764692306518554,
      "step": 11050
    },
    {
      "epoch": 0.444,
      "grad_norm": 0.027620907872915268,
      "learning_rate": 1.11208e-05,
      "loss": 0.2093057632446289,
      "step": 11100
    },
    {
      "epoch": 0.446,
      "grad_norm": 0.8347596526145935,
      "learning_rate": 1.10808e-05,
      "loss": 0.1615082550048828,
      "step": 11150
    },
    {
      "epoch": 0.448,
      "grad_norm": 0.12086744606494904,
      "learning_rate": 1.1040800000000001e-05,
      "loss": 0.23940664291381836,
      "step": 11200
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.031091781333088875,
      "learning_rate": 1.10008e-05,
      "loss": 0.14168652534484863,
      "step": 11250
    },
    {
      "epoch": 0.452,
      "grad_norm": 0.007364481221884489,
      "learning_rate": 1.09608e-05,
      "loss": 0.2883333396911621,
      "step": 11300
    },
    {
      "epoch": 0.454,
      "grad_norm": 0.06185991317033768,
      "learning_rate": 1.09208e-05,
      "loss": 0.1540340232849121,
      "step": 11350
    },
    {
      "epoch": 0.456,
      "grad_norm": 0.06039039418101311,
      "learning_rate": 1.0880800000000001e-05,
      "loss": 0.1765134620666504,
      "step": 11400
    },
    {
      "epoch": 0.458,
      "grad_norm": 0.16305318474769592,
      "learning_rate": 1.08408e-05,
      "loss": 0.14503368377685547,
      "step": 11450
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.011424890719354153,
      "learning_rate": 1.08008e-05,
      "loss": 0.18975378036499024,
      "step": 11500
    },
    {
      "epoch": 0.462,
      "grad_norm": 0.02282707393169403,
      "learning_rate": 1.07608e-05,
      "loss": 0.16630983352661133,
      "step": 11550
    },
    {
      "epoch": 0.464,
      "grad_norm": 0.4835294187068939,
      "learning_rate": 1.07208e-05,
      "loss": 0.26499210357666014,
      "step": 11600
    },
    {
      "epoch": 0.466,
      "grad_norm": 130.1631622314453,
      "learning_rate": 1.06808e-05,
      "loss": 0.2767748260498047,
      "step": 11650
    },
    {
      "epoch": 0.468,
      "grad_norm": 0.007259209640324116,
      "learning_rate": 1.06408e-05,
      "loss": 0.27041412353515626,
      "step": 11700
    },
    {
      "epoch": 0.47,
      "grad_norm": 18.383678436279297,
      "learning_rate": 1.06008e-05,
      "loss": 0.29259456634521486,
      "step": 11750
    },
    {
      "epoch": 0.472,
      "grad_norm": 0.01617930643260479,
      "learning_rate": 1.05608e-05,
      "loss": 0.11520608901977539,
      "step": 11800
    },
    {
      "epoch": 0.474,
      "grad_norm": 113.38539123535156,
      "learning_rate": 1.05208e-05,
      "loss": 0.33981231689453123,
      "step": 11850
    },
    {
      "epoch": 0.476,
      "grad_norm": 0.12409810721874237,
      "learning_rate": 1.04808e-05,
      "loss": 0.07863858222961426,
      "step": 11900
    },
    {
      "epoch": 0.478,
      "grad_norm": 0.040680352598428726,
      "learning_rate": 1.04408e-05,
      "loss": 0.14590706825256347,
      "step": 11950
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.013883001171052456,
      "learning_rate": 1.04008e-05,
      "loss": 0.22227338790893555,
      "step": 12000
    },
    {
      "epoch": 0.482,
      "grad_norm": 11.717848777770996,
      "learning_rate": 1.0360799999999999e-05,
      "loss": 0.21732393264770508,
      "step": 12050
    },
    {
      "epoch": 0.484,
      "grad_norm": 0.9025743007659912,
      "learning_rate": 1.0320800000000001e-05,
      "loss": 0.12749500274658204,
      "step": 12100
    },
    {
      "epoch": 0.486,
      "grad_norm": 0.008243556134402752,
      "learning_rate": 1.0280800000000002e-05,
      "loss": 0.12977375984191894,
      "step": 12150
    },
    {
      "epoch": 0.488,
      "grad_norm": 16.728010177612305,
      "learning_rate": 1.0240800000000002e-05,
      "loss": 0.3029930114746094,
      "step": 12200
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.06468410044908524,
      "learning_rate": 1.0200800000000002e-05,
      "loss": 0.11467902183532715,
      "step": 12250
    },
    {
      "epoch": 0.492,
      "grad_norm": 0.046351704746484756,
      "learning_rate": 1.0160800000000001e-05,
      "loss": 0.195629825592041,
      "step": 12300
    },
    {
      "epoch": 0.494,
      "grad_norm": 0.05727556720376015,
      "learning_rate": 1.0120800000000001e-05,
      "loss": 0.14551311492919922,
      "step": 12350
    },
    {
      "epoch": 0.496,
      "grad_norm": 0.02171432413160801,
      "learning_rate": 1.0080800000000002e-05,
      "loss": 0.14915295600891113,
      "step": 12400
    },
    {
      "epoch": 0.498,
      "grad_norm": 0.1470693200826645,
      "learning_rate": 1.0040800000000002e-05,
      "loss": 0.2626193428039551,
      "step": 12450
    },
    {
      "epoch": 0.5,
      "grad_norm": 198.8639373779297,
      "learning_rate": 1.0000800000000001e-05,
      "loss": 0.22343809127807618,
      "step": 12500
    },
    {
      "epoch": 0.502,
      "grad_norm": 17.14138412475586,
      "learning_rate": 9.960800000000001e-06,
      "loss": 0.2197385025024414,
      "step": 12550
    },
    {
      "epoch": 0.504,
      "grad_norm": 0.019351772964000702,
      "learning_rate": 9.9208e-06,
      "loss": 0.2031705093383789,
      "step": 12600
    },
    {
      "epoch": 0.506,
      "grad_norm": 0.5150542259216309,
      "learning_rate": 9.8808e-06,
      "loss": 0.19277406692504884,
      "step": 12650
    },
    {
      "epoch": 0.508,
      "grad_norm": 0.16315554082393646,
      "learning_rate": 9.8408e-06,
      "loss": 0.08613057136535644,
      "step": 12700
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.0240519680082798,
      "learning_rate": 9.800800000000001e-06,
      "loss": 0.19270965576171875,
      "step": 12750
    },
    {
      "epoch": 0.512,
      "grad_norm": 0.004880854394286871,
      "learning_rate": 9.7608e-06,
      "loss": 0.1853938102722168,
      "step": 12800
    },
    {
      "epoch": 0.514,
      "grad_norm": 0.012523584067821503,
      "learning_rate": 9.720800000000002e-06,
      "loss": 0.19506660461425782,
      "step": 12850
    },
    {
      "epoch": 0.516,
      "grad_norm": 0.08063578605651855,
      "learning_rate": 9.6808e-06,
      "loss": 0.35303440093994143,
      "step": 12900
    },
    {
      "epoch": 0.518,
      "grad_norm": 0.1838543862104416,
      "learning_rate": 9.640800000000001e-06,
      "loss": 0.25387222290039063,
      "step": 12950
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.0729585662484169,
      "learning_rate": 9.600800000000001e-06,
      "loss": 0.15590078353881837,
      "step": 13000
    },
    {
      "epoch": 0.522,
      "grad_norm": 0.05763072147965431,
      "learning_rate": 9.560800000000002e-06,
      "loss": 0.23596282958984374,
      "step": 13050
    },
    {
      "epoch": 0.524,
      "grad_norm": 0.04325046390295029,
      "learning_rate": 9.5208e-06,
      "loss": 0.16483112335205077,
      "step": 13100
    },
    {
      "epoch": 0.526,
      "grad_norm": 0.060362376272678375,
      "learning_rate": 9.4808e-06,
      "loss": 0.2209128952026367,
      "step": 13150
    },
    {
      "epoch": 0.528,
      "grad_norm": 0.019931267946958542,
      "learning_rate": 9.440800000000001e-06,
      "loss": 0.16677068710327148,
      "step": 13200
    },
    {
      "epoch": 0.53,
      "grad_norm": 43.15386962890625,
      "learning_rate": 9.400800000000002e-06,
      "loss": 0.20487508773803711,
      "step": 13250
    },
    {
      "epoch": 0.532,
      "grad_norm": 0.012255207635462284,
      "learning_rate": 9.3608e-06,
      "loss": 0.10681158065795898,
      "step": 13300
    },
    {
      "epoch": 0.534,
      "grad_norm": 0.15884621441364288,
      "learning_rate": 9.3208e-06,
      "loss": 0.24327783584594725,
      "step": 13350
    },
    {
      "epoch": 0.536,
      "grad_norm": 21.401142120361328,
      "learning_rate": 9.280800000000001e-06,
      "loss": 0.18972621917724608,
      "step": 13400
    },
    {
      "epoch": 0.538,
      "grad_norm": 27.402084350585938,
      "learning_rate": 9.240800000000001e-06,
      "loss": 0.29245195388793943,
      "step": 13450
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.13973727822303772,
      "learning_rate": 9.2008e-06,
      "loss": 0.16136016845703124,
      "step": 13500
    },
    {
      "epoch": 0.542,
      "grad_norm": 0.18266014754772186,
      "learning_rate": 9.1608e-06,
      "loss": 0.15537933349609376,
      "step": 13550
    },
    {
      "epoch": 0.544,
      "grad_norm": 0.13084545731544495,
      "learning_rate": 9.1208e-06,
      "loss": 0.21262577056884766,
      "step": 13600
    },
    {
      "epoch": 0.546,
      "grad_norm": 63.69749450683594,
      "learning_rate": 9.080800000000001e-06,
      "loss": 0.36754592895507815,
      "step": 13650
    },
    {
      "epoch": 0.548,
      "grad_norm": 6.2361249923706055,
      "learning_rate": 9.0408e-06,
      "loss": 0.2628676414489746,
      "step": 13700
    },
    {
      "epoch": 0.55,
      "grad_norm": 11.757976531982422,
      "learning_rate": 9.0008e-06,
      "loss": 0.21008676528930664,
      "step": 13750
    },
    {
      "epoch": 0.552,
      "grad_norm": 105.15013885498047,
      "learning_rate": 8.9608e-06,
      "loss": 0.26822675704956056,
      "step": 13800
    },
    {
      "epoch": 0.554,
      "grad_norm": 27.403310775756836,
      "learning_rate": 8.920800000000001e-06,
      "loss": 0.20283952713012696,
      "step": 13850
    },
    {
      "epoch": 0.556,
      "grad_norm": 0.05627162382006645,
      "learning_rate": 8.8808e-06,
      "loss": 0.06236621856689453,
      "step": 13900
    },
    {
      "epoch": 0.558,
      "grad_norm": 0.049458157271146774,
      "learning_rate": 8.8408e-06,
      "loss": 0.11187398910522461,
      "step": 13950
    },
    {
      "epoch": 0.56,
      "grad_norm": 5.273158550262451,
      "learning_rate": 8.8008e-06,
      "loss": 0.12176229476928711,
      "step": 14000
    },
    {
      "epoch": 0.562,
      "grad_norm": 61.337364196777344,
      "learning_rate": 8.760800000000001e-06,
      "loss": 0.14003426551818848,
      "step": 14050
    },
    {
      "epoch": 0.564,
      "grad_norm": 15.455843925476074,
      "learning_rate": 8.7208e-06,
      "loss": 0.12227943420410156,
      "step": 14100
    },
    {
      "epoch": 0.566,
      "grad_norm": 0.006513151805847883,
      "learning_rate": 8.6808e-06,
      "loss": 0.1472171688079834,
      "step": 14150
    },
    {
      "epoch": 0.568,
      "grad_norm": 0.08856083452701569,
      "learning_rate": 8.6408e-06,
      "loss": 0.2364657211303711,
      "step": 14200
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.06987015902996063,
      "learning_rate": 8.6008e-06,
      "loss": 0.21158151626586913,
      "step": 14250
    },
    {
      "epoch": 0.572,
      "grad_norm": 0.04027865454554558,
      "learning_rate": 8.5608e-06,
      "loss": 0.20293052673339843,
      "step": 14300
    },
    {
      "epoch": 0.574,
      "grad_norm": 0.060622844845056534,
      "learning_rate": 8.5208e-06,
      "loss": 0.17076683044433594,
      "step": 14350
    },
    {
      "epoch": 0.576,
      "grad_norm": 0.5800294280052185,
      "learning_rate": 8.4808e-06,
      "loss": 0.24085531234741211,
      "step": 14400
    },
    {
      "epoch": 0.578,
      "grad_norm": 0.3023282587528229,
      "learning_rate": 8.4408e-06,
      "loss": 0.2105865478515625,
      "step": 14450
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.04252561926841736,
      "learning_rate": 8.400800000000001e-06,
      "loss": 0.14695018768310547,
      "step": 14500
    },
    {
      "epoch": 0.582,
      "grad_norm": 0.10989942401647568,
      "learning_rate": 8.360800000000001e-06,
      "loss": 0.21213380813598634,
      "step": 14550
    },
    {
      "epoch": 0.584,
      "grad_norm": 0.008446709252893925,
      "learning_rate": 8.320800000000002e-06,
      "loss": 0.12200400352478027,
      "step": 14600
    },
    {
      "epoch": 0.586,
      "grad_norm": 0.044149018824100494,
      "learning_rate": 8.2808e-06,
      "loss": 0.24852420806884765,
      "step": 14650
    },
    {
      "epoch": 0.588,
      "grad_norm": 46.12885284423828,
      "learning_rate": 8.2408e-06,
      "loss": 0.3170816612243652,
      "step": 14700
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.15048031508922577,
      "learning_rate": 8.200800000000001e-06,
      "loss": 0.2557491111755371,
      "step": 14750
    },
    {
      "epoch": 0.592,
      "grad_norm": 16.603748321533203,
      "learning_rate": 8.160800000000002e-06,
      "loss": 0.11132941246032715,
      "step": 14800
    },
    {
      "epoch": 0.594,
      "grad_norm": 21.75377655029297,
      "learning_rate": 8.1208e-06,
      "loss": 0.09989524841308593,
      "step": 14850
    },
    {
      "epoch": 0.596,
      "grad_norm": 0.0537143312394619,
      "learning_rate": 8.0808e-06,
      "loss": 0.18656925201416016,
      "step": 14900
    },
    {
      "epoch": 0.598,
      "grad_norm": 0.002993373665958643,
      "learning_rate": 8.040800000000001e-06,
      "loss": 0.13939082145690918,
      "step": 14950
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.01647675223648548,
      "learning_rate": 8.000800000000001e-06,
      "loss": 0.22319696426391603,
      "step": 15000
    },
    {
      "epoch": 0.602,
      "grad_norm": 0.03816530108451843,
      "learning_rate": 7.9608e-06,
      "loss": 0.11694090843200683,
      "step": 15050
    },
    {
      "epoch": 0.604,
      "grad_norm": 21.70181655883789,
      "learning_rate": 7.9208e-06,
      "loss": 0.2138089942932129,
      "step": 15100
    },
    {
      "epoch": 0.606,
      "grad_norm": 0.1651764065027237,
      "learning_rate": 7.8808e-06,
      "loss": 0.08407193183898926,
      "step": 15150
    },
    {
      "epoch": 0.608,
      "grad_norm": 0.18176263570785522,
      "learning_rate": 7.840800000000001e-06,
      "loss": 0.05807146072387695,
      "step": 15200
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.10784226655960083,
      "learning_rate": 7.8008e-06,
      "loss": 0.24218536376953126,
      "step": 15250
    },
    {
      "epoch": 0.612,
      "grad_norm": 0.023617921397089958,
      "learning_rate": 7.7608e-06,
      "loss": 0.28085180282592775,
      "step": 15300
    },
    {
      "epoch": 0.614,
      "grad_norm": 95.52407836914062,
      "learning_rate": 7.7208e-06,
      "loss": 0.3456180191040039,
      "step": 15350
    },
    {
      "epoch": 0.616,
      "grad_norm": 0.02866940014064312,
      "learning_rate": 7.680800000000001e-06,
      "loss": 0.13702638626098632,
      "step": 15400
    },
    {
      "epoch": 0.618,
      "grad_norm": 0.011269322596490383,
      "learning_rate": 7.6408e-06,
      "loss": 0.11900111198425294,
      "step": 15450
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.3061913251876831,
      "learning_rate": 7.6008e-06,
      "loss": 0.4061064147949219,
      "step": 15500
    },
    {
      "epoch": 0.622,
      "grad_norm": 0.021552279591560364,
      "learning_rate": 7.5608000000000005e-06,
      "loss": 0.200211124420166,
      "step": 15550
    },
    {
      "epoch": 0.624,
      "grad_norm": 0.18351386487483978,
      "learning_rate": 7.5208e-06,
      "loss": 0.2367427635192871,
      "step": 15600
    },
    {
      "epoch": 0.626,
      "grad_norm": 0.03986113891005516,
      "learning_rate": 7.4808000000000004e-06,
      "loss": 0.03957364559173584,
      "step": 15650
    },
    {
      "epoch": 0.628,
      "grad_norm": 0.0462455190718174,
      "learning_rate": 7.4408e-06,
      "loss": 0.2083330726623535,
      "step": 15700
    },
    {
      "epoch": 0.63,
      "grad_norm": 18.420286178588867,
      "learning_rate": 7.4008e-06,
      "loss": 0.11146328926086425,
      "step": 15750
    },
    {
      "epoch": 0.632,
      "grad_norm": 0.02879483811557293,
      "learning_rate": 7.3608e-06,
      "loss": 0.11823515892028809,
      "step": 15800
    },
    {
      "epoch": 0.634,
      "grad_norm": 0.043962910771369934,
      "learning_rate": 7.3208e-06,
      "loss": 0.174851131439209,
      "step": 15850
    },
    {
      "epoch": 0.636,
      "grad_norm": 0.03966950625181198,
      "learning_rate": 7.2808e-06,
      "loss": 0.088489990234375,
      "step": 15900
    },
    {
      "epoch": 0.638,
      "grad_norm": 0.026411624625325203,
      "learning_rate": 7.2408e-06,
      "loss": 0.13037676811218263,
      "step": 15950
    },
    {
      "epoch": 0.64,
      "grad_norm": 33.499176025390625,
      "learning_rate": 7.2008000000000014e-06,
      "loss": 0.19527706146240234,
      "step": 16000
    },
    {
      "epoch": 0.642,
      "grad_norm": 0.1344176083803177,
      "learning_rate": 7.160800000000001e-06,
      "loss": 0.17038137435913087,
      "step": 16050
    },
    {
      "epoch": 0.644,
      "grad_norm": 0.02619677595794201,
      "learning_rate": 7.120800000000001e-06,
      "loss": 0.27009952545166016,
      "step": 16100
    },
    {
      "epoch": 0.646,
      "grad_norm": 0.07076150178909302,
      "learning_rate": 7.080800000000001e-06,
      "loss": 0.20633865356445313,
      "step": 16150
    },
    {
      "epoch": 0.648,
      "grad_norm": 0.009031977504491806,
      "learning_rate": 7.040800000000001e-06,
      "loss": 0.11030633926391602,
      "step": 16200
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.09800686687231064,
      "learning_rate": 7.000800000000001e-06,
      "loss": 0.06647326469421387,
      "step": 16250
    },
    {
      "epoch": 0.652,
      "grad_norm": 1.4103132486343384,
      "learning_rate": 6.960800000000001e-06,
      "loss": 0.15977087020874023,
      "step": 16300
    },
    {
      "epoch": 0.654,
      "grad_norm": 0.17061664164066315,
      "learning_rate": 6.920800000000001e-06,
      "loss": 0.16136749267578124,
      "step": 16350
    },
    {
      "epoch": 0.656,
      "grad_norm": 0.005602863151580095,
      "learning_rate": 6.880800000000001e-06,
      "loss": 0.09462921142578125,
      "step": 16400
    },
    {
      "epoch": 0.658,
      "grad_norm": 0.005235761404037476,
      "learning_rate": 6.840800000000001e-06,
      "loss": 0.21927366256713868,
      "step": 16450
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.07430405914783478,
      "learning_rate": 6.800800000000001e-06,
      "loss": 0.1756299591064453,
      "step": 16500
    },
    {
      "epoch": 0.662,
      "grad_norm": 0.14587505161762238,
      "learning_rate": 6.7608000000000006e-06,
      "loss": 0.24844751358032227,
      "step": 16550
    },
    {
      "epoch": 0.664,
      "grad_norm": 0.01887807622551918,
      "learning_rate": 6.720800000000001e-06,
      "loss": 0.14396875381469726,
      "step": 16600
    },
    {
      "epoch": 0.666,
      "grad_norm": 0.027307480573654175,
      "learning_rate": 6.6808000000000005e-06,
      "loss": 0.15552212715148925,
      "step": 16650
    },
    {
      "epoch": 0.668,
      "grad_norm": 73.97514343261719,
      "learning_rate": 6.640800000000001e-06,
      "loss": 0.15693056106567382,
      "step": 16700
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.13589341938495636,
      "learning_rate": 6.6008e-06,
      "loss": 0.1937744903564453,
      "step": 16750
    },
    {
      "epoch": 0.672,
      "grad_norm": 0.021519247442483902,
      "learning_rate": 6.560800000000001e-06,
      "loss": 0.13197479248046876,
      "step": 16800
    },
    {
      "epoch": 0.674,
      "grad_norm": 0.10241834819316864,
      "learning_rate": 6.5208e-06,
      "loss": 0.21238601684570313,
      "step": 16850
    },
    {
      "epoch": 0.676,
      "grad_norm": 0.03201303631067276,
      "learning_rate": 6.480800000000001e-06,
      "loss": 0.16546175003051758,
      "step": 16900
    },
    {
      "epoch": 0.678,
      "grad_norm": 0.006474821362644434,
      "learning_rate": 6.4408e-06,
      "loss": 0.10242003440856934,
      "step": 16950
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.004885599948465824,
      "learning_rate": 6.400800000000001e-06,
      "loss": 0.16621591567993163,
      "step": 17000
    },
    {
      "epoch": 0.682,
      "grad_norm": 2.5402188301086426,
      "learning_rate": 6.3608e-06,
      "loss": 0.17159564971923827,
      "step": 17050
    },
    {
      "epoch": 0.684,
      "grad_norm": 0.052432600408792496,
      "learning_rate": 6.3208000000000005e-06,
      "loss": 0.05345672607421875,
      "step": 17100
    },
    {
      "epoch": 0.686,
      "grad_norm": 19.198467254638672,
      "learning_rate": 6.2808e-06,
      "loss": 0.1835355567932129,
      "step": 17150
    },
    {
      "epoch": 0.688,
      "grad_norm": 0.03563689440488815,
      "learning_rate": 6.2408000000000005e-06,
      "loss": 0.10695128440856934,
      "step": 17200
    },
    {
      "epoch": 0.69,
      "grad_norm": 17.953907012939453,
      "learning_rate": 6.2008e-06,
      "loss": 0.26987625122070313,
      "step": 17250
    },
    {
      "epoch": 0.692,
      "grad_norm": 0.5916087031364441,
      "learning_rate": 6.1608e-06,
      "loss": 0.28735464096069335,
      "step": 17300
    },
    {
      "epoch": 0.694,
      "grad_norm": 0.5149540901184082,
      "learning_rate": 6.1208e-06,
      "loss": 0.1367092990875244,
      "step": 17350
    },
    {
      "epoch": 0.696,
      "grad_norm": 0.06265994906425476,
      "learning_rate": 6.0808e-06,
      "loss": 0.18515623092651368,
      "step": 17400
    },
    {
      "epoch": 0.698,
      "grad_norm": 0.037340905517339706,
      "learning_rate": 6.0408e-06,
      "loss": 0.22043142318725586,
      "step": 17450
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.05658204108476639,
      "learning_rate": 6.0008e-06,
      "loss": 0.14492608070373536,
      "step": 17500
    },
    {
      "epoch": 0.702,
      "grad_norm": 17.493555068969727,
      "learning_rate": 5.9608000000000014e-06,
      "loss": 0.19976966857910156,
      "step": 17550
    },
    {
      "epoch": 0.704,
      "grad_norm": 11.175132751464844,
      "learning_rate": 5.920800000000001e-06,
      "loss": 0.12459502220153809,
      "step": 17600
    },
    {
      "epoch": 0.706,
      "grad_norm": 0.00949840247631073,
      "learning_rate": 5.880800000000001e-06,
      "loss": 0.13469782829284668,
      "step": 17650
    },
    {
      "epoch": 0.708,
      "grad_norm": 0.0707385390996933,
      "learning_rate": 5.840800000000001e-06,
      "loss": 0.3144736480712891,
      "step": 17700
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.272565096616745,
      "learning_rate": 5.800800000000001e-06,
      "loss": 0.10969143867492676,
      "step": 17750
    },
    {
      "epoch": 0.712,
      "grad_norm": 0.028333982452750206,
      "learning_rate": 5.760800000000001e-06,
      "loss": 0.21759698867797853,
      "step": 17800
    },
    {
      "epoch": 0.714,
      "grad_norm": 0.02820795215666294,
      "learning_rate": 5.720800000000001e-06,
      "loss": 0.19953689575195313,
      "step": 17850
    },
    {
      "epoch": 0.716,
      "grad_norm": 10.178458213806152,
      "learning_rate": 5.680800000000001e-06,
      "loss": 0.2355262565612793,
      "step": 17900
    },
    {
      "epoch": 0.718,
      "grad_norm": 0.059599339962005615,
      "learning_rate": 5.640800000000001e-06,
      "loss": 0.27919652938842776,
      "step": 17950
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.06411116570234299,
      "learning_rate": 5.600800000000001e-06,
      "loss": 0.1648042106628418,
      "step": 18000
    },
    {
      "epoch": 0.722,
      "grad_norm": 0.5861387252807617,
      "learning_rate": 5.560800000000001e-06,
      "loss": 0.08549369812011719,
      "step": 18050
    },
    {
      "epoch": 0.724,
      "grad_norm": 0.011241885833442211,
      "learning_rate": 5.5208000000000006e-06,
      "loss": 0.20767778396606446,
      "step": 18100
    },
    {
      "epoch": 0.726,
      "grad_norm": 0.013930507935583591,
      "learning_rate": 5.480800000000001e-06,
      "loss": 0.17177949905395506,
      "step": 18150
    },
    {
      "epoch": 0.728,
      "grad_norm": 0.47068002820014954,
      "learning_rate": 5.4408000000000005e-06,
      "loss": 0.1015264892578125,
      "step": 18200
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.07081198692321777,
      "learning_rate": 5.400800000000001e-06,
      "loss": 0.2034274482727051,
      "step": 18250
    },
    {
      "epoch": 0.732,
      "grad_norm": 0.014062485657632351,
      "learning_rate": 5.3608e-06,
      "loss": 0.12473195075988769,
      "step": 18300
    },
    {
      "epoch": 0.734,
      "grad_norm": 0.0812186524271965,
      "learning_rate": 5.320800000000001e-06,
      "loss": 0.2402997589111328,
      "step": 18350
    },
    {
      "epoch": 0.736,
      "grad_norm": 0.030209803953766823,
      "learning_rate": 5.2808e-06,
      "loss": 0.1786838150024414,
      "step": 18400
    },
    {
      "epoch": 0.738,
      "grad_norm": 0.06690768152475357,
      "learning_rate": 5.240800000000001e-06,
      "loss": 0.12761547088623046,
      "step": 18450
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.008697975426912308,
      "learning_rate": 5.2008e-06,
      "loss": 0.12449844360351563,
      "step": 18500
    },
    {
      "epoch": 0.742,
      "grad_norm": 0.18528248369693756,
      "learning_rate": 5.160800000000001e-06,
      "loss": 0.13807853698730468,
      "step": 18550
    },
    {
      "epoch": 0.744,
      "grad_norm": 0.06556831300258636,
      "learning_rate": 5.1208e-06,
      "loss": 0.23368860244750977,
      "step": 18600
    },
    {
      "epoch": 0.746,
      "grad_norm": 0.06598854809999466,
      "learning_rate": 5.0808000000000006e-06,
      "loss": 0.15899766921997072,
      "step": 18650
    },
    {
      "epoch": 0.748,
      "grad_norm": 0.03711741417646408,
      "learning_rate": 5.0408e-06,
      "loss": 0.30436880111694337,
      "step": 18700
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.08581706881523132,
      "learning_rate": 5.0008000000000005e-06,
      "loss": 0.19551111221313477,
      "step": 18750
    },
    {
      "epoch": 0.752,
      "grad_norm": 0.027831796556711197,
      "learning_rate": 4.960800000000001e-06,
      "loss": 0.2026415252685547,
      "step": 18800
    },
    {
      "epoch": 0.754,
      "grad_norm": 0.09741834551095963,
      "learning_rate": 4.9208e-06,
      "loss": 0.14664706230163574,
      "step": 18850
    },
    {
      "epoch": 0.756,
      "grad_norm": 14.143145561218262,
      "learning_rate": 4.880800000000001e-06,
      "loss": 0.20452884674072266,
      "step": 18900
    },
    {
      "epoch": 0.758,
      "grad_norm": 0.018162082880735397,
      "learning_rate": 4.8408e-06,
      "loss": 0.23446857452392578,
      "step": 18950
    },
    {
      "epoch": 0.76,
      "grad_norm": 16.154874801635742,
      "learning_rate": 4.800800000000001e-06,
      "loss": 0.3965106201171875,
      "step": 19000
    },
    {
      "epoch": 0.762,
      "grad_norm": 0.25999540090560913,
      "learning_rate": 4.7608e-06,
      "loss": 0.0909910774230957,
      "step": 19050
    },
    {
      "epoch": 0.764,
      "grad_norm": 0.029924850910902023,
      "learning_rate": 4.720800000000001e-06,
      "loss": 0.18087738037109374,
      "step": 19100
    },
    {
      "epoch": 0.766,
      "grad_norm": 0.05473686009645462,
      "learning_rate": 4.6808e-06,
      "loss": 0.19012537002563476,
      "step": 19150
    },
    {
      "epoch": 0.768,
      "grad_norm": 0.023920467123389244,
      "learning_rate": 4.6408000000000005e-06,
      "loss": 0.07809106349945068,
      "step": 19200
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.04727635532617569,
      "learning_rate": 4.6008e-06,
      "loss": 0.2645709228515625,
      "step": 19250
    },
    {
      "epoch": 0.772,
      "grad_norm": 0.012491746805608273,
      "learning_rate": 4.5608000000000004e-06,
      "loss": 0.13299986839294434,
      "step": 19300
    },
    {
      "epoch": 0.774,
      "grad_norm": 0.07640309631824493,
      "learning_rate": 4.5208e-06,
      "loss": 0.0751239824295044,
      "step": 19350
    },
    {
      "epoch": 0.776,
      "grad_norm": 0.05814855173230171,
      "learning_rate": 4.4808e-06,
      "loss": 0.16151481628417969,
      "step": 19400
    },
    {
      "epoch": 0.778,
      "grad_norm": 0.16538669168949127,
      "learning_rate": 4.4408e-06,
      "loss": 0.19779224395751954,
      "step": 19450
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.4098033010959625,
      "learning_rate": 4.4008e-06,
      "loss": 0.0941595458984375,
      "step": 19500
    },
    {
      "epoch": 0.782,
      "grad_norm": 0.05688263848423958,
      "learning_rate": 4.360800000000001e-06,
      "loss": 0.14204611778259277,
      "step": 19550
    },
    {
      "epoch": 0.784,
      "grad_norm": 0.13046342134475708,
      "learning_rate": 4.3208e-06,
      "loss": 0.1027258014678955,
      "step": 19600
    },
    {
      "epoch": 0.786,
      "grad_norm": 0.12233789265155792,
      "learning_rate": 4.280800000000001e-06,
      "loss": 0.1178996753692627,
      "step": 19650
    },
    {
      "epoch": 0.788,
      "grad_norm": 14.01382064819336,
      "learning_rate": 4.2408e-06,
      "loss": 0.12862433433532716,
      "step": 19700
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.014368546195328236,
      "learning_rate": 4.2008000000000005e-06,
      "loss": 0.06714575290679932,
      "step": 19750
    },
    {
      "epoch": 0.792,
      "grad_norm": 0.1257704645395279,
      "learning_rate": 4.1608e-06,
      "loss": 0.21469516754150392,
      "step": 19800
    },
    {
      "epoch": 0.794,
      "grad_norm": 0.01582382433116436,
      "learning_rate": 4.1208000000000004e-06,
      "loss": 0.2638735771179199,
      "step": 19850
    },
    {
      "epoch": 0.796,
      "grad_norm": 0.059501245617866516,
      "learning_rate": 4.0808e-06,
      "loss": 0.16906244277954102,
      "step": 19900
    },
    {
      "epoch": 0.798,
      "grad_norm": 20.42607879638672,
      "learning_rate": 4.0408e-06,
      "loss": 0.16220495223999024,
      "step": 19950
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.024089904502034187,
      "learning_rate": 4.0008e-06,
      "loss": 0.17695991516113282,
      "step": 20000
    },
    {
      "epoch": 0.802,
      "grad_norm": 0.03715713694691658,
      "learning_rate": 3.9608e-06,
      "loss": 0.1116585636138916,
      "step": 20050
    },
    {
      "epoch": 0.804,
      "grad_norm": 40.76752853393555,
      "learning_rate": 3.9208e-06,
      "loss": 0.2547716903686523,
      "step": 20100
    },
    {
      "epoch": 0.806,
      "grad_norm": 0.09051261097192764,
      "learning_rate": 3.8808e-06,
      "loss": 0.3038968086242676,
      "step": 20150
    },
    {
      "epoch": 0.808,
      "grad_norm": 10.773870468139648,
      "learning_rate": 3.8408e-06,
      "loss": 0.23137842178344725,
      "step": 20200
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.02722393535077572,
      "learning_rate": 3.8008e-06,
      "loss": 0.15272786140441894,
      "step": 20250
    },
    {
      "epoch": 0.812,
      "grad_norm": 32.47344207763672,
      "learning_rate": 3.7608000000000005e-06,
      "loss": 0.07976148128509522,
      "step": 20300
    },
    {
      "epoch": 0.814,
      "grad_norm": 1.6618674993515015,
      "learning_rate": 3.7208000000000004e-06,
      "loss": 0.1551830291748047,
      "step": 20350
    },
    {
      "epoch": 0.816,
      "grad_norm": 0.01539564598351717,
      "learning_rate": 3.6808000000000004e-06,
      "loss": 0.09040003776550293,
      "step": 20400
    },
    {
      "epoch": 0.818,
      "grad_norm": 0.004018957260996103,
      "learning_rate": 3.6408000000000004e-06,
      "loss": 0.10623161315917969,
      "step": 20450
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.01304378267377615,
      "learning_rate": 3.6008000000000003e-06,
      "loss": 0.14411932945251466,
      "step": 20500
    },
    {
      "epoch": 0.822,
      "grad_norm": 0.0276484414935112,
      "learning_rate": 3.5608000000000003e-06,
      "loss": 0.20755590438842775,
      "step": 20550
    },
    {
      "epoch": 0.824,
      "grad_norm": 0.007375522516667843,
      "learning_rate": 3.5208000000000002e-06,
      "loss": 0.15679357528686524,
      "step": 20600
    },
    {
      "epoch": 0.826,
      "grad_norm": 0.006357009522616863,
      "learning_rate": 3.4808e-06,
      "loss": 0.2415229606628418,
      "step": 20650
    },
    {
      "epoch": 0.828,
      "grad_norm": 59.1948356628418,
      "learning_rate": 3.4408e-06,
      "loss": 0.18405269622802733,
      "step": 20700
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.1420498490333557,
      "learning_rate": 3.4008e-06,
      "loss": 0.2739320373535156,
      "step": 20750
    },
    {
      "epoch": 0.832,
      "grad_norm": 0.003203931963071227,
      "learning_rate": 3.3608e-06,
      "loss": 0.14636941909790038,
      "step": 20800
    },
    {
      "epoch": 0.834,
      "grad_norm": 15.441559791564941,
      "learning_rate": 3.3208e-06,
      "loss": 0.11393064498901367,
      "step": 20850
    },
    {
      "epoch": 0.836,
      "grad_norm": 0.509157657623291,
      "learning_rate": 3.2808e-06,
      "loss": 0.07961508274078369,
      "step": 20900
    },
    {
      "epoch": 0.838,
      "grad_norm": 0.855453610420227,
      "learning_rate": 3.2408e-06,
      "loss": 0.11454194068908691,
      "step": 20950
    },
    {
      "epoch": 0.84,
      "grad_norm": 73.86428833007812,
      "learning_rate": 3.2008e-06,
      "loss": 0.17827024459838867,
      "step": 21000
    },
    {
      "epoch": 0.842,
      "grad_norm": 0.004881939850747585,
      "learning_rate": 3.1608000000000007e-06,
      "loss": 0.20649232864379882,
      "step": 21050
    },
    {
      "epoch": 0.844,
      "grad_norm": 0.001501444960013032,
      "learning_rate": 3.1208000000000007e-06,
      "loss": 0.12812528610229493,
      "step": 21100
    },
    {
      "epoch": 0.846,
      "grad_norm": 0.3203953802585602,
      "learning_rate": 3.0808000000000006e-06,
      "loss": 0.11271591186523437,
      "step": 21150
    },
    {
      "epoch": 0.848,
      "grad_norm": 0.023442380130290985,
      "learning_rate": 3.0408000000000006e-06,
      "loss": 0.11996989250183106,
      "step": 21200
    },
    {
      "epoch": 0.85,
      "grad_norm": 21.34766960144043,
      "learning_rate": 3.0008000000000006e-06,
      "loss": 0.22172698974609376,
      "step": 21250
    },
    {
      "epoch": 0.852,
      "grad_norm": 1.059183120727539,
      "learning_rate": 2.9608000000000005e-06,
      "loss": 0.08947571754455566,
      "step": 21300
    },
    {
      "epoch": 0.854,
      "grad_norm": 0.015574452467262745,
      "learning_rate": 2.9208000000000005e-06,
      "loss": 0.22061965942382813,
      "step": 21350
    },
    {
      "epoch": 0.856,
      "grad_norm": 106.72688293457031,
      "learning_rate": 2.8808000000000004e-06,
      "loss": 0.24235540390014648,
      "step": 21400
    },
    {
      "epoch": 0.858,
      "grad_norm": 0.09231657534837723,
      "learning_rate": 2.8408000000000004e-06,
      "loss": 0.16798675537109375,
      "step": 21450
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.042497094720602036,
      "learning_rate": 2.8008000000000004e-06,
      "loss": 0.1660476303100586,
      "step": 21500
    },
    {
      "epoch": 0.862,
      "grad_norm": 0.07603675872087479,
      "learning_rate": 2.7608000000000003e-06,
      "loss": 0.30590396881103515,
      "step": 21550
    },
    {
      "epoch": 0.864,
      "grad_norm": 0.009298293851315975,
      "learning_rate": 2.7208000000000003e-06,
      "loss": 0.17868146896362305,
      "step": 21600
    },
    {
      "epoch": 0.866,
      "grad_norm": 0.032521605491638184,
      "learning_rate": 2.6808000000000002e-06,
      "loss": 0.15973112106323242,
      "step": 21650
    },
    {
      "epoch": 0.868,
      "grad_norm": 0.007978222332894802,
      "learning_rate": 2.6408e-06,
      "loss": 0.07154187202453613,
      "step": 21700
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.2232510894536972,
      "learning_rate": 2.6008e-06,
      "loss": 0.21295394897460937,
      "step": 21750
    },
    {
      "epoch": 0.872,
      "grad_norm": 0.40609046816825867,
      "learning_rate": 2.5608e-06,
      "loss": 0.17351322174072265,
      "step": 21800
    },
    {
      "epoch": 0.874,
      "grad_norm": 0.0021396491210907698,
      "learning_rate": 2.5208000000000005e-06,
      "loss": 0.25787412643432617,
      "step": 21850
    },
    {
      "epoch": 0.876,
      "grad_norm": 0.0018819923279806972,
      "learning_rate": 2.4808e-06,
      "loss": 0.17348918914794922,
      "step": 21900
    },
    {
      "epoch": 0.878,
      "grad_norm": 0.0291985385119915,
      "learning_rate": 2.4408e-06,
      "loss": 0.27353700637817385,
      "step": 21950
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.01414664275944233,
      "learning_rate": 2.4008e-06,
      "loss": 0.18199827194213866,
      "step": 22000
    },
    {
      "epoch": 0.882,
      "grad_norm": 0.03802641108632088,
      "learning_rate": 2.3608000000000003e-06,
      "loss": 0.17064075469970702,
      "step": 22050
    },
    {
      "epoch": 0.884,
      "grad_norm": 20.735607147216797,
      "learning_rate": 2.3208000000000003e-06,
      "loss": 0.1404767608642578,
      "step": 22100
    },
    {
      "epoch": 0.886,
      "grad_norm": 0.2759571373462677,
      "learning_rate": 2.2808000000000003e-06,
      "loss": 0.2466021728515625,
      "step": 22150
    },
    {
      "epoch": 0.888,
      "grad_norm": 0.06008930131793022,
      "learning_rate": 2.2408000000000002e-06,
      "loss": 0.16292331695556642,
      "step": 22200
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.15912848711013794,
      "learning_rate": 2.2008e-06,
      "loss": 0.05764148235321045,
      "step": 22250
    },
    {
      "epoch": 0.892,
      "grad_norm": 0.7821410894393921,
      "learning_rate": 2.1608e-06,
      "loss": 0.15849753379821777,
      "step": 22300
    },
    {
      "epoch": 0.894,
      "grad_norm": 0.09140083193778992,
      "learning_rate": 2.1208e-06,
      "loss": 0.18711124420166014,
      "step": 22350
    },
    {
      "epoch": 0.896,
      "grad_norm": 1.756563663482666,
      "learning_rate": 2.0808e-06,
      "loss": 0.0913187313079834,
      "step": 22400
    },
    {
      "epoch": 0.898,
      "grad_norm": 0.05487188324332237,
      "learning_rate": 2.0408000000000004e-06,
      "loss": 0.12886788368225097,
      "step": 22450
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.018655972555279732,
      "learning_rate": 2.0008000000000004e-06,
      "loss": 0.17481424331665038,
      "step": 22500
    },
    {
      "epoch": 0.902,
      "grad_norm": 0.0683656558394432,
      "learning_rate": 1.9608000000000004e-06,
      "loss": 0.23554233551025391,
      "step": 22550
    },
    {
      "epoch": 0.904,
      "grad_norm": 0.03071027249097824,
      "learning_rate": 1.9208000000000003e-06,
      "loss": 0.21026691436767578,
      "step": 22600
    },
    {
      "epoch": 0.906,
      "grad_norm": 0.6001371145248413,
      "learning_rate": 1.8808e-06,
      "loss": 0.1956205940246582,
      "step": 22650
    },
    {
      "epoch": 0.908,
      "grad_norm": 0.18167071044445038,
      "learning_rate": 1.8408e-06,
      "loss": 0.12333870887756347,
      "step": 22700
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.3110808730125427,
      "learning_rate": 1.8008e-06,
      "loss": 0.17317602157592774,
      "step": 22750
    },
    {
      "epoch": 0.912,
      "grad_norm": 0.08671605587005615,
      "learning_rate": 1.7608e-06,
      "loss": 0.09949910163879394,
      "step": 22800
    },
    {
      "epoch": 0.914,
      "grad_norm": 0.10239540040493011,
      "learning_rate": 1.7208000000000003e-06,
      "loss": 0.059596738815307616,
      "step": 22850
    },
    {
      "epoch": 0.916,
      "grad_norm": 0.12966808676719666,
      "learning_rate": 1.6808000000000003e-06,
      "loss": 0.19620676040649415,
      "step": 22900
    },
    {
      "epoch": 0.918,
      "grad_norm": 0.010206814855337143,
      "learning_rate": 1.6408000000000002e-06,
      "loss": 0.053620223999023435,
      "step": 22950
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.010190865956246853,
      "learning_rate": 1.6008000000000002e-06,
      "loss": 0.1611083984375,
      "step": 23000
    },
    {
      "epoch": 0.922,
      "grad_norm": 2.8508670330047607,
      "learning_rate": 1.5608000000000002e-06,
      "loss": 0.27917816162109377,
      "step": 23050
    },
    {
      "epoch": 0.924,
      "grad_norm": 0.008635615929961205,
      "learning_rate": 1.5208000000000001e-06,
      "loss": 0.17754350662231444,
      "step": 23100
    },
    {
      "epoch": 0.926,
      "grad_norm": 0.12881116569042206,
      "learning_rate": 1.4808e-06,
      "loss": 0.1659703254699707,
      "step": 23150
    },
    {
      "epoch": 0.928,
      "grad_norm": 0.20458713173866272,
      "learning_rate": 1.4408000000000002e-06,
      "loss": 0.10122114181518554,
      "step": 23200
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.040339622646570206,
      "learning_rate": 1.4008000000000002e-06,
      "loss": 0.16084794998168944,
      "step": 23250
    },
    {
      "epoch": 0.932,
      "grad_norm": 2.9345529079437256,
      "learning_rate": 1.3608000000000002e-06,
      "loss": 0.22965837478637696,
      "step": 23300
    },
    {
      "epoch": 0.934,
      "grad_norm": 23.3936824798584,
      "learning_rate": 1.3208000000000001e-06,
      "loss": 0.18596408843994142,
      "step": 23350
    },
    {
      "epoch": 0.936,
      "grad_norm": 53.0247688293457,
      "learning_rate": 1.2808e-06,
      "loss": 0.2617290687561035,
      "step": 23400
    },
    {
      "epoch": 0.938,
      "grad_norm": 95.03706359863281,
      "learning_rate": 1.2408e-06,
      "loss": 0.10527369499206543,
      "step": 23450
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.020713577046990395,
      "learning_rate": 1.2008000000000002e-06,
      "loss": 0.15649716377258302,
      "step": 23500
    },
    {
      "epoch": 0.942,
      "grad_norm": 0.019854364916682243,
      "learning_rate": 1.1608000000000002e-06,
      "loss": 0.16028615951538086,
      "step": 23550
    },
    {
      "epoch": 0.944,
      "grad_norm": 0.08567952364683151,
      "learning_rate": 1.1208000000000001e-06,
      "loss": 0.2615439224243164,
      "step": 23600
    },
    {
      "epoch": 0.946,
      "grad_norm": 5.441422939300537,
      "learning_rate": 1.0808e-06,
      "loss": 0.22561172485351563,
      "step": 23650
    },
    {
      "epoch": 0.948,
      "grad_norm": 0.034570325165987015,
      "learning_rate": 1.0408e-06,
      "loss": 0.18403600692749023,
      "step": 23700
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.2996751070022583,
      "learning_rate": 1.0008e-06,
      "loss": 0.15010913848876953,
      "step": 23750
    },
    {
      "epoch": 0.952,
      "grad_norm": 0.025542156770825386,
      "learning_rate": 9.608e-07,
      "loss": 0.1419021224975586,
      "step": 23800
    },
    {
      "epoch": 0.954,
      "grad_norm": 0.09182516485452652,
      "learning_rate": 9.208e-07,
      "loss": 0.1435483169555664,
      "step": 23850
    },
    {
      "epoch": 0.956,
      "grad_norm": 0.002959831152111292,
      "learning_rate": 8.808000000000001e-07,
      "loss": 0.13029742240905762,
      "step": 23900
    },
    {
      "epoch": 0.958,
      "grad_norm": 0.02171393483877182,
      "learning_rate": 8.408000000000001e-07,
      "loss": 0.1446998405456543,
      "step": 23950
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.048714980483055115,
      "learning_rate": 8.008e-07,
      "loss": 0.0726349401473999,
      "step": 24000
    },
    {
      "epoch": 0.962,
      "grad_norm": 0.07451385259628296,
      "learning_rate": 7.608e-07,
      "loss": 0.06411352157592773,
      "step": 24050
    },
    {
      "epoch": 0.964,
      "grad_norm": 0.06520979106426239,
      "learning_rate": 7.208000000000002e-07,
      "loss": 0.11807893753051758,
      "step": 24100
    },
    {
      "epoch": 0.966,
      "grad_norm": 2.782536268234253,
      "learning_rate": 6.808000000000001e-07,
      "loss": 0.19375614166259766,
      "step": 24150
    },
    {
      "epoch": 0.968,
      "grad_norm": 0.15494292974472046,
      "learning_rate": 6.408000000000001e-07,
      "loss": 0.10994034767150879,
      "step": 24200
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.02889258787035942,
      "learning_rate": 6.008e-07,
      "loss": 0.08983649253845215,
      "step": 24250
    },
    {
      "epoch": 0.972,
      "grad_norm": 0.24361346662044525,
      "learning_rate": 5.608e-07,
      "loss": 0.0622443151473999,
      "step": 24300
    },
    {
      "epoch": 0.974,
      "grad_norm": 0.06042616441845894,
      "learning_rate": 5.208000000000001e-07,
      "loss": 0.06986998081207275,
      "step": 24350
    },
    {
      "epoch": 0.976,
      "grad_norm": 0.13649103045463562,
      "learning_rate": 4.808e-07,
      "loss": 0.19261425018310546,
      "step": 24400
    },
    {
      "epoch": 0.978,
      "grad_norm": 0.03732801228761673,
      "learning_rate": 4.4080000000000003e-07,
      "loss": 0.09524796485900879,
      "step": 24450
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.011879226192831993,
      "learning_rate": 4.008e-07,
      "loss": 0.1511538314819336,
      "step": 24500
    },
    {
      "epoch": 0.982,
      "grad_norm": 0.008801523596048355,
      "learning_rate": 3.6080000000000005e-07,
      "loss": 0.13542985916137695,
      "step": 24550
    },
    {
      "epoch": 0.984,
      "grad_norm": 0.036036863923072815,
      "learning_rate": 3.208e-07,
      "loss": 0.10907691001892089,
      "step": 24600
    },
    {
      "epoch": 0.986,
      "grad_norm": 0.07827965170145035,
      "learning_rate": 2.808e-07,
      "loss": 0.03531454086303711,
      "step": 24650
    },
    {
      "epoch": 0.988,
      "grad_norm": 0.035009533166885376,
      "learning_rate": 2.4080000000000004e-07,
      "loss": 0.14466408729553223,
      "step": 24700
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.0020862023811787367,
      "learning_rate": 2.0080000000000002e-07,
      "loss": 0.13593603134155274,
      "step": 24750
    },
    {
      "epoch": 0.992,
      "grad_norm": 0.004636015277355909,
      "learning_rate": 1.608e-07,
      "loss": 0.24770885467529297,
      "step": 24800
    },
    {
      "epoch": 0.994,
      "grad_norm": 20.52764129638672,
      "learning_rate": 1.2080000000000002e-07,
      "loss": 0.18349483489990234,
      "step": 24850
    },
    {
      "epoch": 0.996,
      "grad_norm": 0.006652842275798321,
      "learning_rate": 8.080000000000001e-08,
      "loss": 0.15208053588867188,
      "step": 24900
    },
    {
      "epoch": 0.998,
      "grad_norm": 0.35115423798561096,
      "learning_rate": 4.080000000000001e-08,
      "loss": 0.1995543670654297,
      "step": 24950
    },
    {
      "epoch": 1.0,
      "grad_norm": 14.132715225219727,
      "learning_rate": 8.000000000000001e-10,
      "loss": 0.1930132293701172,
      "step": 25000
    }
  ],
  "logging_steps": 50,
  "max_steps": 25000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 6577835443200000.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
